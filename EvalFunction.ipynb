{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvalFunction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Lr4ekZEjU0",
        "colab_type": "text"
      },
      "source": [
        "# Term Proximity Retrieval Model in SQL using DuckDB and MonetDBLite\n",
        "\n",
        "This notebook is a work in progress for the Information Retrieval course research project. A number of retrievel models are implemented in SQL queries that can be run with two database systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzHGaGElGGZ8",
        "colab_type": "text"
      },
      "source": [
        "## Index\n",
        "\n",
        "A preliminary index of the Robust04 data set was first [downloaded from Jimmy Lin's Dropbox](https://www.dropbox.com/s/mdoly9sjdalh44x/lucene-index.robust04.pos%2Bdocvectors%2Brawdocs.tar.gz). Then the [OldDog](https://github.com/Chriskamphuis/olddog) code from Chris Kamphuis and Arjen de Vries was modified to work with more than one leaf. Their code was further modified to store the collection frequency of each term and the term frequency of each term in each document. The modified code was run, which resulted in three CSV tables. \n",
        "\n",
        "The *dict* table houses termid, term, document frequency, and collection frequency data. The *docs* table houses name, docid, and document length information. And finally, the *terms* table houses the termid, docid, position, and term frequency data.\n",
        "\n",
        "These three tables are put in an archive, so that they can be easily [downloaded from Dropbox](https://www.dropbox.com/s/5qwq3gn6rto98sd/Robust04%2Bpos%2Btf%2Bcf.rar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkE-y3cGS1MO",
        "colab_type": "code",
        "outputId": "a840bf6c-4996-45a7-a003-0cecda8d3276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "!wget -O Robust04.rar https://dl.dropboxusercontent.com/s/wvr3nnreq8ee082/Robust04%2Bpos%2Bcf%2Bqueries%2Bqrels.rar?dl=0\n",
        "!unrar e -o+ Robust04.rar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 16:13:48--  https://dl.dropboxusercontent.com/s/wvr3nnreq8ee082/Robust04%2Bpos%2Bcf%2Bqueries%2Bqrels.rar?dl=0\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460288656 (439M) [application/rar]\n",
            "Saving to: ‘Robust04.rar’\n",
            "\n",
            "Robust04.rar        100%[===================>] 438.96M  15.1MB/s    in 16m 28s \n",
            "\n",
            "2019-11-25 16:30:17 (455 KB/s) - ‘Robust04.rar’ saved [460288656/460288656]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Robust04.rar\n",
            "\n",
            "Extracting  docs.csv                                                     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  qrels.csv                                                    \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  queries_test.csv                                             \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  terms.csv                                                    \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  dict.csv                                                     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XbFCaWPzLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LXIae-4JC7G",
        "colab_type": "text"
      },
      "source": [
        "## Databases\n",
        "\n",
        "Both DuckDB and MonetDBLite will be used to test the differences between them on a number of dimensions, during the evaluation phase of the research.\n",
        "\n",
        "Google Colab does not pre-install these packages, so that is why we need to do `pip install`. This takes about 5 minutes for DuckDB, so please already run the next cell, before reading on.\n",
        "\n",
        "Here, we have made two classes that do the necessary tasks that we need the databases to do.\n",
        "\n",
        "MonetDB cannot be used, as it requires an external Java MonetDB server, and the project was to be made with the Python APIs. That leaves us with MonetDBLite. For some reason, they have taken out the Python DB API for MonetDBLite (the `Cursor` class and `cursor.execute()` function). We could enable it by modifying the source code, but the program also needs to work for other people on other computers. So we just stuck to the Simple API of MonetDBLite. Another titbit, MonetDBLite cannot be initialized in the memory. If you go over some memory bandwith threshold, the whole database stops working. So, MonetDBLite needs to be initialized in storage. The performance difference is not that big on Google Colab, but it did matter on a local runtime.\n",
        "\n",
        "When initializing the database objects, the index tables are automatically added. So you only have to initialize them once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOnPbiYTEph",
        "colab_type": "code",
        "outputId": "52ea06cc-98e0-44ea-b5c5-cf3f601bd586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "!pip install duckdb\n",
        "import duckdb\n",
        "\n",
        "class DuckDB(object):\n",
        "  \"\"\"\n",
        "  Class that houses all the DuckDB functionalities.\n",
        "\n",
        "  Attributes:\n",
        "    c         = [Cursor] database cursor of DuckDB\n",
        "    C         = [int] number of indexed terms\n",
        "    N         = [int] number of indexed documents\n",
        "    avgdl     = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database=':memory:',\n",
        "               dict='dict.csv',\n",
        "               docs='docs.csv',\n",
        "               terms='terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes DuckDB database with index and statistics.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    # initialize database\n",
        "    con = duckdb.connect(database)\n",
        "    self.c = con.cursor()\n",
        "\n",
        "    # copy dictionary CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                                    \",term   VARCHAR \"\n",
        "                                    \",df     INTEGER \"\n",
        "                                    \",cf     INTEGER)\")\n",
        "    self.c.execute(\"COPY dict \"\n",
        "                   \"FROM '\" + dict + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy documents CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE docs(name  VARCHAR \"\n",
        "                                    \",docid INTEGER \"\n",
        "                                    \",len   INTEGER \"\n",
        "                                    \",temp  INTEGER)\")\n",
        "    self.c.execute(\"COPY docs \"\n",
        "                   \"FROM '\" + docs + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy terms CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                                     \",docid  INTEGER \"\n",
        "                                     \",pos    INTEGER \"\n",
        "                                     \",tf     INTEGER)\")\n",
        "    self.c.execute(\"COPY terms \"\n",
        "                   \"FROM '\" + terms + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in DuckDB database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    # convert search query in to SQL query\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    # make new or replace old query table\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS query\")\n",
        "    self.c.execute(\"CREATE TABLE query(term VARCHAR)\")\n",
        "    self.c.execute(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    # bookkeeping\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def make_queries(self, queries, qrels):\n",
        "    \"\"\"\n",
        "    Makes queries and qrels tables in DuckDB database filled with\n",
        "    queryid, term pairs and queryid, docid relevance, respectively.\n",
        "\n",
        "    Args:\n",
        "      queries = [str] filename for search queries CSV\n",
        "      qrels   = [str] filename for relevance judgements CSV\n",
        "    \"\"\"\n",
        "    # copy queries CSV into DuckDB database\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS queries\")\n",
        "    self.c.execute(\"CREATE TABLE queries(queryid INTEGER \"\n",
        "                                       \",term    VARCHAR \"\n",
        "                                       \",len     INTEGER)\")\n",
        "    self.c.execute(\"COPY queries \"\n",
        "                   \"FROM '\" + queries + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy relevance judgements CSV into DuckDB database\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS qrels\")\n",
        "    self.c.execute(\"CREATE TABLE qrels(queryid INTEGER \"\n",
        "                                     \",name    VARCHAR \"\n",
        "                                     \",rel     INTEGER)\")\n",
        "    self.c.execute(\"COPY qrels \"\n",
        "                   \"FROM '\" + qrels + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on DuckDB database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by DuckDB\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = self.c.execute(query)\n",
        "    return out.fetchdf()\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = self.c.execute(\"SELECT SUM(dict.cf) \"\n",
        "                       \"FROM dict\")\n",
        "    return C.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = self.c.execute(\"SELECT COUNT(*) \"\n",
        "                       \"FROM docs\")\n",
        "    return N.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = self.c.execute(\"SELECT AVG(docs.len) \"\n",
        "                           \"FROM docs\")\n",
        "    return avgdl.fetchdf().iloc[0, 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting duckdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/45/37215c3e2fc9c5b94e379a0b3b85a388107d3d626cde8cfacea377ba1696/duckdb-0.1.1.tar.gz (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from duckdb) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from duckdb) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23->duckdb) (1.12.0)\n",
            "Building wheels for collected packages: duckdb\n",
            "  Building wheel for duckdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for duckdb: filename=duckdb-0.1.1-cp36-cp36m-linux_x86_64.whl size=1947901 sha256=6002060daeec96f0c111d671f61e55be81c590121e29facbc16493a5baa02256\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/2e/81/8061e62cf80a0ea73a4657d5807c46a93105440af5921e828c\n",
            "Successfully built duckdb\n",
            "Installing collected packages: duckdb\n",
            "Successfully installed duckdb-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YojwuWrTd6N",
        "colab_type": "code",
        "outputId": "4c1ec3a3-fe00-4096-9ab1-b79a26a81c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "!pip install monetdblite\n",
        "import monetdblite as m\n",
        "import pandas as pd\n",
        "\n",
        "class MonetDBLite(object):\n",
        "  \"\"\" \n",
        "  Class that houses all the MonetDBLite functionalities. \n",
        "\n",
        "  Attributes:\n",
        "    C     = [int] number of indexed terms\n",
        "    N     = [int] number of indexed documents\n",
        "    avgdl = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database='/tmp/MonetDBLite Database',\n",
        "               dict='dict.csv',\n",
        "               docs='docs.csv',\n",
        "               terms='terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes MonetDBLite database with index.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    # MonetDBLite expects an absolute path\n",
        "    dict = os.path.join('/content', dict)\n",
        "    docs = os.path.join('/content', docs)\n",
        "    terms = os.path.join('/content', terms)\n",
        "\n",
        "    # initialize database\n",
        "    m.init(database)\n",
        "\n",
        "    # copy dictionary CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                           \",term   VARCHAR(99) \"\n",
        "                           \",df     INTEGER \"\n",
        "                           \",cf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO dict \"\n",
        "          \"FROM '\" + dict + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy documents CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE docs(name  VARCHAR(99) \"\n",
        "                           \",docid INTEGER \"\n",
        "                           \",len   INTEGER \"\n",
        "                           \",temp  INTEGER)\") \n",
        "    m.sql(\"COPY INTO docs \"\n",
        "          \"FROM '\" + docs + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy terms CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                            \",docid  INTEGER \"\n",
        "                            \",pos    INTEGER \"\n",
        "                            \",tf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO terms \"\n",
        "          \"FROM '\" + terms + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in MonetDBLite database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    # convert search query in to SQL query\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    # make new or replace old query table\n",
        "    m.sql(\"DROP TABLE IF EXISTS query\")\n",
        "    m.sql(\"CREATE TABLE query(term VARCHAR(99))\")\n",
        "    m.sql(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    # bookkeeping\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def make_queries(self, queries, qrels):\n",
        "    \"\"\"\n",
        "    Makes queries and qrels tables in MonetDBLite database filled with\n",
        "    queryid, term pairs and queryid, docid relevance, respectively.\n",
        "\n",
        "    Args:\n",
        "      queries = [str] filename for search queries CSV\n",
        "      qrels   = [str] filename for relevance judgements CSV\n",
        "    \"\"\"\n",
        "    # MonetDBLite expects an absolute path\n",
        "    queries = os.path.join('/content', queries)\n",
        "    qrels = os.path.join('/content', qrels)\n",
        "\n",
        "    # copy queries CSV into MonetDBLite database\n",
        "    m.sql(\"DROP TABLE IF EXISTS queries\")\n",
        "    m.sql(\"CREATE TABLE queries(queryid INTEGER \"\n",
        "                              \",term    VARCHAR(99) \"\n",
        "                              \",len     INTEGER)\")\n",
        "    m.sql(\"COPY INTO queries \"\n",
        "          \"FROM '\" + queries + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy relevance judgements CSV into MonetDBLite database\n",
        "    m.sql(\"DROP TABLE IF EXISTS qrels\")\n",
        "    m.sql(\"CREATE TABLE qrels(queryid INTEGER \"\n",
        "                            \",name    VARCHAR(99) \"\n",
        "                            \",rel     INTEGER)\")\n",
        "    m.sql(\"COPY INTO qrels \"\n",
        "          \"FROM '\" + qrels + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on MonetDBLite database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by MonetDBLite\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = m.sql(query)\n",
        "    return pd.DataFrame.from_dict(out)\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = m.sql(\"SELECT SUM(dict.cf) \"\n",
        "              \"FROM dict\")\n",
        "    return pd.DataFrame.from_dict(C).iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = m.sql(\"SELECT COUNT(*) \"\n",
        "              \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(N).iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = m.sql(\"SELECT AVG(docs.len) \"\n",
        "                  \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(avgdl).iloc[0, 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting monetdblite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/6a/d49c0b03c62c81098ecd42c6e2ed037979355d00797326a6acd2090f4822/monetdblite-0.6.3-cp36-cp36m-manylinux1_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.20->monetdblite) (1.12.0)\n",
            "Installing collected packages: monetdblite\n",
            "Successfully installed monetdblite-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3r4KeAvMEh7",
        "colab_type": "text"
      },
      "source": [
        "## Retriever\n",
        "\n",
        "The next class houses the function for retrieving the relevant documents given a number of options, `retrieve()`. The private methods (starting with an underscore) could really use some help. So please only use the `retrieve()` function further into the file. Perhaps we will clean up the mess later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p2vSKIYU9H4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class Retriever(object):\n",
        "  \"\"\" Class to do document retrieval with term proximity using databases. \"\"\"     \n",
        "  def retrieve(self,\n",
        "               query, \n",
        "               db,\n",
        "               con_query=True, \n",
        "               pre_select='kld', \n",
        "               tp=True,\n",
        "               k=30,\n",
        "               sum=True,\n",
        "               mu=0.8, # totally not sure about this hyper-parameter\n",
        "               k1=1.2,\n",
        "               b=0.75,\n",
        "               num_docs=20,\n",
        "               max_span=5):\n",
        "    \"\"\"\n",
        "    Function that retreives documents with a Retrieval Status Value (RSV)\n",
        "    based on term-proximity (TP) weighting, Okapi BM25 or Kullback-Leibler\n",
        "    Divergence. When opting for TP, k documents can be pre-selected with\n",
        "    the Okapi BM25 or Kullback-Leibler Divergence retrieval models.\n",
        "\n",
        "    Args:\n",
        "      query      = [[str]] the tokenized and normalied query\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      tp         = [bool] whether to do the term proximity at all\n",
        "      k          = [int] maximum number of documents to retrieve with\n",
        "                         the pre-selection retrieval model\n",
        "      sum        = [bool] whether to sum the pre-selection and term \n",
        "                          proximity scores for the final score\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "      max_span   = [int] maximum distance, in number of terms, for a term\n",
        "                         pair to be included in the term proximity score\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output.\n",
        "    \"\"\"\n",
        "    # add the search query as a table to the database\n",
        "    db.make_query(*query)\n",
        "\n",
        "    # determine the SQL query\n",
        "    sql = (self._qterms(pre_select, tp) +\n",
        "           self._qtermstf(pre_select, tp) +\n",
        "           self._condocs(db, con_query, tp) +\n",
        "           self._pre_select_subscores(db, con_query, pre_select, mu, k1, b) +\n",
        "           self._topkdocs(pre_select, k) + \n",
        "           self._pairs(con_query, pre_select, tp, max_span) +\n",
        "           self._tpscores(db, tp, k1, b) +\n",
        "           self._scores(pre_select, tp, sum, num_docs))\n",
        "    print('Query: {}'.format(sql))\n",
        "    \n",
        "    # get the elapsed time and the results after executing the SQL query\n",
        "    time = datetime.now()\n",
        "    out = db.execute_query(sql)\n",
        "    time_delta = datetime.now() - time\n",
        "    print('Query time: {}'.format(time_delta))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def retrieve_all(self,\n",
        "                   queries,\n",
        "                   qrels,\n",
        "                   db,\n",
        "                   con_query=True, \n",
        "                   pre_select='kld', \n",
        "                   tp=True,\n",
        "                   k=30,\n",
        "                   sum=True,\n",
        "                   mu=0.8, # totally not sure about this hyper-parameter\n",
        "                   k1=1.2,\n",
        "                   b=0.75,\n",
        "                   num_docs=20,\n",
        "                   max_span=5):\n",
        "    \"\"\"\n",
        "    Function that retrieves a document ranking for all queries with a\n",
        "    Retrieval Status Value (RSV) based on term-proximity (TP) weighting,\n",
        "    Okapi BM25 or Kullback-Leibler Divergence. When opting for TP, k\n",
        "    documents can be pre-selected with the Okapi BM25 or Kullback-Leibler\n",
        "    Divergence retrieval models. The relevance judgements are also added.\n",
        "\n",
        "    Args:\n",
        "      queries    = [str] filename for search queries CSV\n",
        "      qrels      = [str] filename for relevance judgements CSV\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      tp         = [bool] whether to do the term proximity at all\n",
        "      k          = [int] maximum number of documents to retrieve with\n",
        "                         the pre-selection retrieval model per query\n",
        "      sum        = [bool] whether to sum the pre-selection and term \n",
        "                          proximity scores for the final score\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      num_docs   = [int] maximum number of documents to retrieve per query\n",
        "      max_span   = [int] maximum distance, in number of terms, for a term\n",
        "                         pair to be included in the term proximity score\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output.\n",
        "    \"\"\"\n",
        "    # add the queries and qrels tables to the database\n",
        "    db.make_queries(queries, qrels)\n",
        "\n",
        "    # determine the SQL query\n",
        "    sql = (self._qterms(pre_select, tp, True) +\n",
        "           self._qtermstf(pre_select, tp, True) +\n",
        "           self._condocs(db, con_query, tp, True) +\n",
        "           self._pre_select_subscores(db, con_query, pre_select, mu, k1, b, True) +\n",
        "           self._topkdocs(pre_select, k, True) + \n",
        "           self._pairs(con_query, pre_select, tp, max_span, True) +\n",
        "           self._tpscores(db, tp, k1, b, True) +\n",
        "           self._scores(pre_select, tp, sum, num_docs, True) +\n",
        "           self._qrels())    \n",
        "    print('Query: {}'.format(sql))\n",
        "\n",
        "    # get the elapsed time and the results after executing the SQL query\n",
        "    time = datetime.now()\n",
        "    out = db.execute_query(sql)\n",
        "    time_delta = datetime.now() - time\n",
        "    print('Query time: {}'.format(time_delta))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def _qterms(self, pre_select, tp, all=False):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, including the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term  \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\"WITH qtermids \"\n",
        "                  \"AS (SELECT dict.termid \"\n",
        "                            \",dict.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM dict \"\n",
        "                      \"{}\"\n",
        "                      \") \"\n",
        "             \"{}\")\n",
        "    \n",
        "    if tp:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"{}\",\n",
        "                           \", qterms \"\n",
        "                                \"AS (SELECT terms.termid \"\n",
        "                                          \",terms.docid \"\n",
        "                                          \",terms.pos \"\n",
        "                                          \",terms.tf \"\n",
        "                                          \",qtermids.df \"\n",
        "                                          \"{}\"\n",
        "                                    \"FROM terms \"\n",
        "                                    \"JOIN qtermids \"\n",
        "                                    \"ON terms.termid = qtermids.termid\"\n",
        "                                    \") \")\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",dict.cf \"\n",
        "                            \"{}\",\n",
        "                            \"{}\",\n",
        "                            \",qtermids.cf \"\n",
        "                            \"{}\")\n",
        "      \n",
        "      if all:\n",
        "        return query.format(\",queries.queryid \"\n",
        "                            \",queries.len \",\n",
        "                            \"JOIN queries \"\n",
        "                            \"ON dict.term = queries.term\",\n",
        "                            \",qtermids.queryid \"\n",
        "                            \",qtermids.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"JOIN query \"\n",
        "                            \"ON dict.term = query.term\",\n",
        "                            \"\")  \n",
        "    else:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",dict.cf \"\n",
        "                            \"{}\",\n",
        "                            \"{}\",\n",
        "                            \"{}\")\n",
        "      \n",
        "      if all:\n",
        "        return query.format(\",queries.queryid \"\n",
        "                            \",queries.len \",\n",
        "                            \"JOIN queries \"\n",
        "                            \"ON dict.term = queries.term\",\n",
        "                            \"\")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"JOIN query \"\n",
        "                            \"ON dict.term = query.term\",\n",
        "                            \"\")\n",
        "\n",
        "  def _qtermstf(self, pre_select, tp, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, excluding the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term\n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "    \n",
        "    query = (\", qtermstfrows \"\n",
        "                  \"AS (SELECT qterms.termid \"\n",
        "                            \",qterms.docid \"\n",
        "                            \",qterms.tf \"\n",
        "                            \"{}\"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                               \"OVER(PARTITION BY {}qterms.termid, qterms.docid \"\n",
        "                                    \"ORDER BY qterms.pos\"\n",
        "                                    \")\"\n",
        "                              \") AS row \"\n",
        "                      \"{}\" \n",
        "                      \") \"\n",
        "             \", qtermstf \"\n",
        "                  \"AS (SELECT qtermstfrows.termid \"\n",
        "                            \",qtermstfrows.docid \"\n",
        "                            \",qtermstfrows.tf \"\n",
        "                            \",qtermstfrows.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM qtermstfrows \"\n",
        "                      \"WHERE qtermstfrows.row = 1\"\n",
        "                      \") \")\n",
        "\n",
        "    if tp:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",qterms.df \"\n",
        "                             \",qterms.cf \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM qterms\",\n",
        "                             \",qtermstfrows.cf \"\n",
        "                             \"{}\")\n",
        "      elif pre_select == 'okapi':\n",
        "        query = query.format(\",qterms.df \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM qterms\",\n",
        "                             \"{}\")\n",
        "        \n",
        "      if all:\n",
        "        return query.format(\",qterms.queryid \"\n",
        "                            \",qterms.len \",\n",
        "                            \"qterms.queryid ,\",\n",
        "                            \",qtermstfrows.queryid \"\n",
        "                            \",qtermstfrows.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\",\n",
        "                            \"\")\n",
        "    else:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",qtermids.df \"\n",
        "                             \",qtermids.cf \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM terms AS qterms \"\n",
        "                             \"JOIN qtermids \"\n",
        "                             \"ON qterms.termid = qtermids.termid\",\n",
        "                             \",qtermstfrows.cf \"\n",
        "                             \"{}\")  \n",
        "      elif pre_select == 'okapi':\n",
        "        query = query.format(\",qtermids.df \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM terms AS qterms \"\n",
        "                             \"JOIN qtermids \"\n",
        "                             \"ON qterms.termid = qtermids.termid\",\n",
        "                             \"{}\") \n",
        "         \n",
        "      if all:\n",
        "        return query.format(\",qtermids.queryid \"\n",
        "                            \",qtermids.len \",\n",
        "                            \"qtermids.queryid ,\",\n",
        "                            \",qtermstfrows.queryid \"\n",
        "                            \",qtermstfrows.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\",\n",
        "                            \"\")\n",
        "\n",
        "  def _condocs(self, db, con_query, tp, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to documents that contain all the query terms.\n",
        "\n",
        "    Args:\n",
        "      db        = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query = [bool] whether all query terms need to be in\n",
        "                         the document for it to be retrieved\n",
        "      tp        = [bool] whether to do the term proximity\n",
        "      all       = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.                         \n",
        "    \"\"\"\n",
        "    if not con_query:\n",
        "      return \"\"\n",
        "      \n",
        "    query = (\", condocs \"\n",
        "                  \"AS (SELECT qterms.docid \"\n",
        "                      \"{}\"\n",
        "                      \"FROM {} AS qterms \"\n",
        "                      \"GROUP BY qterms.docid \"\n",
        "                      \"{}\"\n",
        "                      \"HAVING COUNT(DISTINCT qterms.termid) = {}\"\n",
        "                      \") \")\n",
        "    if tp:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"qterms\",\n",
        "                           \"{}\",\n",
        "                           \"{}\")\n",
        "    else:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"qtermstf\",\n",
        "                           \"{}\",\n",
        "                           \"{}\")\n",
        "      \n",
        "    if all:\n",
        "      return query.format(\",qterms.queryid \",\n",
        "                          \",qterms.queryid \",\n",
        "                          \"MIN(qterms.len)\")\n",
        "    else:\n",
        "      return query.format(\"\",\n",
        "                          \"\",\n",
        "                          db.len_query)\n",
        "\n",
        "  def _pre_select_subscores(self, db, con_query, pre_select, mu, k1, b, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute a score for each \n",
        "    query term-document pair, according to the pre-selection\n",
        "    retrieval model.\n",
        "\n",
        "    Args:\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved     \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "    \n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "\n",
        "    if pre_select == 'kld':\n",
        "      query = (\", kldsubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \"{}\"\n",
        "                              \",( LOG({:f}+tf*{:f}/cf)\"              \n",
        "                                  \"+\" \n",
        "                                 \"LOG(1/({:f}+docs.len))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(\"{}\", mu, db.C, mu, \"{}\")\n",
        "    elif pre_select == 'okapi':\n",
        "      query = (\", okapisubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \"{}\"\n",
        "                              \",( LOG(({:f}-df+0.5)/(df+0.5))*tf*({:f}+1)\"\n",
        "                                  \"/\"\n",
        "                                 \"(tf+{:f}*(1-{:f}+{:f}*docs.len/{:f}))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(\"{}\", db.N, k1, k1, b, b, db.avgdl, \"{}\")\n",
        "\n",
        "    if con_query:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"JOIN condocs \"\n",
        "                           \"ON qtermstf.docid = condocs.docid \"\n",
        "                           \"{}\")      \n",
        "      if all:\n",
        "        return query.format(\",qtermstf.queryid \",\n",
        "                            \"AND qtermstf.queryid = condocs.queryid \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\")\n",
        "    else:\n",
        "      if all:\n",
        "        return query.format(\",qtermstf.queryid \",\n",
        "                            \"\")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\")\n",
        "\n",
        "  def _topkdocs(self, pre_select, k, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the pre-selection scores,\n",
        "    according to the pre-selection retrieval model, and retrieve\n",
        "    the top k documents.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      k          = [int] maximum number of documents retrieved with\n",
        "                         the pre-selection retrieval model\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", topdocs \"\n",
        "                  \"AS (SELECT subscores.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(subscores.subscore) AS score \"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                                \"OVER({}ORDER BY SUM(subscores.subscore) DESC)\"\n",
        "                              \") AS rank \"\n",
        "                      \"FROM {} AS subscores \"\n",
        "                      \"GROUP BY subscores.docid\"\n",
        "                      \"{}\"\n",
        "                      \") \"\n",
        "             \", topkdocs \"\n",
        "                  \"AS (SELECT topdocs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",topdocs.score \"\n",
        "                      \"FROM topdocs \"\n",
        "                      \"WHERE topdocs.rank BETWEEN 1 AND {}\"\n",
        "                      \") \")\n",
        "    \n",
        "    if all:\n",
        "      query = query.format(\",subscores.queryid \",\n",
        "                           \"PARTITION BY subscores.queryid \",\n",
        "                           \"{}\",\n",
        "                           \" ,subscores.queryid\",\n",
        "                           \",topdocs.queryid \",\n",
        "                           \"{:d}\")\n",
        "    else:\n",
        "      query = query.format(\"\",\n",
        "                           \"\",\n",
        "                           \"{}\",\n",
        "                           \"\",\n",
        "                           \"\",\n",
        "                           \"{:d}\")\n",
        "    \n",
        "    if pre_select == 'kld':\n",
        "      return query.format(\"kldsubscores\",\n",
        "                          k)\n",
        "    elif pre_select == 'okapi':\n",
        "      return query.format(\"okapisubscores\",\n",
        "                          k)\n",
        "\n",
        "  def _pairs(self, con_query, pre_select, tp, max_span, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term pair instance (tpi) for\n",
        "    each query term pair within a span of max_span terms.\n",
        "\n",
        "    Args:\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved                          \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model  \n",
        "      tp         = [bool] whether to do the term proximity                   \n",
        "      max_span   = [int] the maximum span, in terms, of a term pair to\n",
        "                        include in the term proximity score\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", pairs \"\n",
        "                  \"AS (SELECT qterms1.termid AS termid1 \"\n",
        "                            \",qterms2.termid AS termid2 \"\n",
        "                            \"{}\"\n",
        "                            \",qterms1.docid \"\n",
        "                            \",1.0/(qterms1.pos-qterms2.pos) AS tpi \"\n",
        "                            \",( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df \"\n",
        "                                    \"ELSE qterms2.df \"\n",
        "                               \"END\"\n",
        "                              \") AS maxdf \"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                               \"OVER(PARTITION BY qterms1.termid \"\n",
        "                                                \",qterms2.termid \"\n",
        "                                                \"{}\"\n",
        "                                                \",qterms1.docid \"\n",
        "                                    \"ORDER BY qterms1.pos)\"\n",
        "                              \") AS row \"\n",
        "                      \"FROM qterms AS qterms1 \"\n",
        "                      \"{}\"\n",
        "                      \"{}\"\n",
        "                      \"JOIN qterms AS qterms2 \"\n",
        "                      \"ON qterms1.docid = qterms2.docid AND \"\n",
        "                         \"{}\"\n",
        "                         \"NOT qterms1.termid = qterms2.termid AND \"\n",
        "                         \"qterms1.pos-qterms2.pos BETWEEN 1 AND {:d}\"\n",
        "                      \") \")\n",
        "    \n",
        "    if all:\n",
        "      if con_query:\n",
        "        query = query.format(\",qterms1.queryid \",\n",
        "                             \",qterms1.queryid \",\n",
        "                             \"JOIN condocs ON qterms1.queryid = condocs.queryid \"\n",
        "                             \"AND qterms1.docid = condocs.docid \",\n",
        "                             \"{}\",\n",
        "                             \"qterms1.queryid = qterms2.queryid AND \",\n",
        "                             max_span)\n",
        "      else:\n",
        "        query = query.format(\",qterms1.queryid \",\n",
        "                             \",qterms1.queryid \",\n",
        "                             \"\",\n",
        "                             \"{}\",\n",
        "                             \"qterms1.queryid = qterms2.queryid AND \",\n",
        "                             max_span)\n",
        "        \n",
        "      if pre_select == 'none':\n",
        "        return query.format(\"\")\n",
        "      else:\n",
        "        return query.format(\"JOIN topkdocs ON qterms1.queryid = topkdocs.queryid \"\n",
        "                            \"AND qterms1.docid = topkdocs.docid \")        \n",
        "    else:\n",
        "      if con_query:\n",
        "        query = query.format(\"\",\n",
        "                             \"\",\n",
        "                             \"JOIN condocs ON qterms1.docid = condocs.docid \",\n",
        "                             \"{}\",\n",
        "                             \"\",\n",
        "                             max_span)\n",
        "      else:\n",
        "        query = query.format(\"\",\n",
        "                             \"\",\n",
        "                             \"\",\n",
        "                             \"{}\",\n",
        "                             \"\",\n",
        "                             max_span)\n",
        "        \n",
        "      if pre_select == 'none':\n",
        "        return query.format(\"\")\n",
        "      else:\n",
        "        return query.format(\"JOIN topkdocs ON qterms1.docid = topkdocs.docid \")\n",
        "      \n",
        "  def _tpscores(self, db, tp, k1, b, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term proximity score.\n",
        "\n",
        "    Args:      \n",
        "      db  = [DuckDB|MonetDBLite] database that stores the index\n",
        "      tp  = [bool] whether to do the term proximity\n",
        "      k1  = [float] hyper-parameter for Okapi BM25\n",
        "      b   = [float] hyper-parameter for Okapi BM25\n",
        "      all = [bool] whether to retrieve a document ranking for all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "      \n",
        "    query = (\", tpisums \"\n",
        "                  \"AS (SELECT pairs.termid1 \"\n",
        "                            \",pairs.termid2 \"\n",
        "                            \",pairs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(pairs.tpi) AS tpisum \"\n",
        "                      \"FROM pairs \"              \n",
        "                      \"GROUP BY pairs.termid1 \"\n",
        "                              \",pairs.termid2 \"\n",
        "                              \",pairs.docid\"\n",
        "                              \"{}\"\n",
        "                      \") \"\n",
        "            \", tpsubscores \"\n",
        "                  \"AS (SELECT pairs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",( LOG(({:f}-maxdf+0.5)/(maxdf+0.5))*tpisum*({:f}+1)\"\n",
        "                                \"/\"\n",
        "                              \"(tpisum+{:f}*(1-{:f}+{:f}*docs.len/{:f}))\"\n",
        "                              \") AS tpsubscore \"\n",
        "                      \"FROM pairs \"\n",
        "                      \"JOIN tpisums \"\n",
        "                      \"ON pairs.termid1 = tpisums.termid1 AND \"\n",
        "                        \"pairs.termid2 = tpisums.termid2 AND \"\n",
        "                        \"pairs.docid = tpisums.docid \"\n",
        "                        \"{}\"\n",
        "                      \"JOIN docs \"\n",
        "                      \"ON pairs.docid = docs.docid \"\n",
        "                      \"WHERE pairs.row = 1\"\n",
        "                      \") \"\n",
        "            \", tpscores \"\n",
        "                  \"AS (SELECT tpsubscores.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(tpsubscores.tpsubscore) AS tpscore \"\n",
        "                      \"FROM tpsubscores \"\n",
        "                      \"GROUP BY tpsubscores.docid\"\n",
        "                      \"{}\"\n",
        "                      \") \")\n",
        "\n",
        "    if all:\n",
        "      return query.format(\",pairs.queryid \",\n",
        "                          \" ,pairs.queryid\",\n",
        "                          \",pairs.queryid \",\n",
        "                          db.N,\n",
        "                          k1,\n",
        "                          k1,\n",
        "                          b,\n",
        "                          b,\n",
        "                          db.avgdl,\n",
        "                          \"AND pairs.queryid = tpisums.queryid \",\n",
        "                          \",tpsubscores.queryid \",\n",
        "                          \" ,tpsubscores.queryid\")\n",
        "    else:\n",
        "      return query.format(\"\",\n",
        "                          \"\",\n",
        "                          \"\",\n",
        "                          db.N,\n",
        "                          k1,\n",
        "                          k1,\n",
        "                          b,\n",
        "                          b,\n",
        "                          db.avgdl,\n",
        "                          \"\",\n",
        "                          \"\",\n",
        "                          \"\")\n",
        "\n",
        "  def _scores(self, pre_select, tp, sum, num_docs, all=False):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve or compute the final document scores.\n",
        "\n",
        "    Args:      \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      sum        = [bool] whether to sum the pre-select and term \n",
        "                          proximity scores for the final score\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "      all        = [bool] whether to retrieve a document ranking\n",
        "                          for all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if all:\n",
        "      query = (\", scores \"\n",
        "                    \"AS ({}) \"\n",
        "                \", topndocs \"\n",
        "                    \"AS (SELECT scores.queryid \"\n",
        "                              \",scores.docid \"\n",
        "                              \",scores.score \"\n",
        "                              \",scores.rank \"\n",
        "                        \"FROM scores \"\n",
        "                        \"WHERE scores.rank BETWEEN 1 and {:d}\"\n",
        "                        \") \")\n",
        "      \n",
        "      if not tp:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.queryid \"\n",
        "                                  \",topkdocs.score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY topkdocs.queryid \"\n",
        "                                          \"ORDER BY topkdocs.score DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs\",\n",
        "                            num_docs)\n",
        "      elif pre_select == 'none' or not sum:\n",
        "        return query.format(\"SELECT tpscores.docid \"\n",
        "                                  \",tpscores.queryid \"\n",
        "                                  \",tpscores.tpscore AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY tpscores.queryid \"\n",
        "                                          \"ORDER BY tpscores.tpscore DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM tpscores\",\n",
        "                            num_docs)\n",
        "      else:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.queryid \"\n",
        "                                  \",( topkdocs.score\"\n",
        "                                      \"+\"\n",
        "                                    \"COALESCE(tpscores.tpscore, 0)\"\n",
        "                                    \") AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY topkdocs.queryid \"\n",
        "                                          \"ORDER BY topkdocs.score\"\n",
        "                                                    \"+\"\n",
        "                                                   \"COALESCE(tpscores.tpscore, 0) \"\n",
        "                                                \"DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs \"\n",
        "                            \"LEFT JOIN tpscores \"\n",
        "                            \"ON topkdocs.docid = tpscores.docid AND \"\n",
        "                               \"topkdocs.queryid = tpscores.queryid\",\n",
        "                            num_docs)\n",
        "    else:           \n",
        "      query = (\", scores \"\n",
        "                    \"AS ({}) \"\n",
        "                \"SELECT scores.docid \"\n",
        "                      \",scores.score \"\n",
        "                      \",scores.rank \"\n",
        "                \"FROM scores \"\n",
        "                \"WHERE scores.rank BETWEEN 1 AND {:d}\")\n",
        "      \n",
        "      if not tp:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY topkdocs.score DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs\",\n",
        "                            num_docs)\n",
        "      elif pre_select == 'none' or not sum:\n",
        "        return query.format(\"SELECT tpscores.docid \"\n",
        "                                  \",tpscores.tpscore AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY tpscores.tpscore DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM tpscores\",\n",
        "                            num_docs)\n",
        "      else:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",( topkdocs.score\"\n",
        "                                      \"+\"\n",
        "                                    \"COALESCE(tpscores.tpscore, 0)\"\n",
        "                                    \") AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY topkdocs.score\"\n",
        "                                                    \"+\"\n",
        "                                                   \"COALESCE(tpscores.tpscore, 0) \"\n",
        "                                          \"DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs \"\n",
        "                            \"LEFT JOIN tpscores \"\n",
        "                            \"ON topkdocs.docid = tpscores.docid\",\n",
        "                            num_docs)\n",
        "        \n",
        "  def _qrels(self):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve the relevance judgement for each\n",
        "    retrieved query-document pair.\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\"SELECT topndocs.queryid \"\n",
        "                   \",docs.name \"\n",
        "                   \",topndocs.score \"\n",
        "                   \",topndocs.rank \"\n",
        "                   \",COALESCE(qrels.rel, 0) AS rel \"\n",
        "             \"FROM topndocs \"\n",
        "             \"JOIN docs \"\n",
        "             \"ON topndocs.docid = docs.docid \"\n",
        "             \"LEFT JOIN qrels \"\n",
        "             \"ON topndocs.queryid = qrels.queryid AND \"\n",
        "                \"docs.name = qrels.name\")\n",
        "    return query"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPKySlkvO4-0",
        "colab_type": "text"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Both databases are initialized, which loads the indices in the databases and makes them ready for execution. This can take about 5 minutes, so time for coffee!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0DVuHD8yaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck = DuckDB()\n",
        "monet = MonetDBLite()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvRhkp_6eto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.sql(\"DROP TABLE terms\")\n",
        "m.sql(\"DROP TABLE dict\")\n",
        "m.sql(\"DROP TABLE docs\")\n",
        "m.sql(\"DROP TABLE IF EXISTS queries\")\n",
        "m.sql(\"DROP TABLE IF EXISTS qrels\")\n",
        "m.shutdown()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXXbESd9PoiE",
        "colab_type": "text"
      },
      "source": [
        "The `Retriever` class does not have a constructor, so initializing it is a bit meaningless. I still prefer to put it in a class to hide the private methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvqmT_067S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retriever = Retriever()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltD5O2EfJJiZ",
        "colab_type": "code",
        "outputId": "5d26efde-dd4d-496c-a21d-5fb19f650b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "duck_rels = retriever.retrieve_all('queries_test.csv', 'qrels.csv', duck, con_query=False, num_docs=30)\n",
        "monet_rels = retriever.retrieve_all('queries_test.csv', 'qrels.csv', monet, con_query=False, num_docs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf ,queries.queryid ,queries.len FROM dict JOIN queries ON dict.term = queries.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df ,qtermids.cf ,qtermids.queryid ,qtermids.len FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,qterms.cf ,qterms.queryid ,qterms.len ,( ROW_NUMBER() OVER(PARTITION BY qterms.queryid ,qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf ,qtermstfrows.queryid ,qtermstfrows.len FROM qtermstfrows WHERE qtermstfrows.row = 1) , kldsubscores AS (SELECT qtermstf.docid ,qtermstf.queryid ,( LOG(0.800000+tf*109623557.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,subscores.queryid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(PARTITION BY subscores.queryid ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid ,subscores.queryid) , topkdocs AS (SELECT topdocs.docid ,topdocs.queryid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.queryid ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.queryid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN topkdocs ON qterms1.queryid = topkdocs.queryid AND qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND qterms1.queryid = qterms2.queryid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid) , tpsubscores AS (SELECT pairs.docid ,pairs.queryid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid AND pairs.queryid = tpisums.queryid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,tpsubscores.queryid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid ,tpsubscores.queryid) , scores AS (SELECT topkdocs.docid ,topkdocs.queryid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(PARTITION BY topkdocs.queryid ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid AND topkdocs.queryid = tpscores.queryid) , topndocs AS (SELECT scores.queryid ,scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 and 30) SELECT topndocs.queryid ,docs.name ,topndocs.score ,topndocs.rank ,COALESCE(qrels.rel, 0) AS rel FROM topndocs JOIN docs ON topndocs.docid = docs.docid LEFT JOIN qrels ON topndocs.queryid = qrels.queryid AND docs.name = qrels.name\n",
            "Query time: 0:00:16.868212\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf ,queries.queryid ,queries.len FROM dict JOIN queries ON dict.term = queries.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df ,qtermids.cf ,qtermids.queryid ,qtermids.len FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,qterms.cf ,qterms.queryid ,qterms.len ,( ROW_NUMBER() OVER(PARTITION BY qterms.queryid ,qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf ,qtermstfrows.queryid ,qtermstfrows.len FROM qtermstfrows WHERE qtermstfrows.row = 1) , kldsubscores AS (SELECT qtermstf.docid ,qtermstf.queryid ,( LOG(0.800000+tf*109623557.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,subscores.queryid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(PARTITION BY subscores.queryid ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid ,subscores.queryid) , topkdocs AS (SELECT topdocs.docid ,topdocs.queryid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.queryid ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.queryid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN topkdocs ON qterms1.queryid = topkdocs.queryid AND qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND qterms1.queryid = qterms2.queryid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid) , tpsubscores AS (SELECT pairs.docid ,pairs.queryid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid AND pairs.queryid = tpisums.queryid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,tpsubscores.queryid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid ,tpsubscores.queryid) , scores AS (SELECT topkdocs.docid ,topkdocs.queryid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(PARTITION BY topkdocs.queryid ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid AND topkdocs.queryid = tpscores.queryid) , topndocs AS (SELECT scores.queryid ,scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 and 30) SELECT topndocs.queryid ,docs.name ,topndocs.score ,topndocs.rank ,COALESCE(qrels.rel, 0) AS rel FROM topndocs JOIN docs ON topndocs.docid = docs.docid LEFT JOIN qrels ON topndocs.queryid = qrels.queryid AND docs.name = qrels.name\n",
            "Query time: 0:00:00.625464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mpB_RwLjrxY",
        "colab_type": "code",
        "outputId": "48687459-f729-4485-819a-ba308563c8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "duck_rels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "      <th>rel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>319</td>\n",
              "      <td>LA051690-0087</td>\n",
              "      <td>3.465312</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>319</td>\n",
              "      <td>FT934-5009</td>\n",
              "      <td>3.391935</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>319</td>\n",
              "      <td>FT933-13604</td>\n",
              "      <td>3.388628</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940921-0-00153</td>\n",
              "      <td>3.327169</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>319</td>\n",
              "      <td>FT924-15359</td>\n",
              "      <td>3.310323</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>319</td>\n",
              "      <td>LA121689-0080</td>\n",
              "      <td>3.269254</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>319</td>\n",
              "      <td>FT924-3293</td>\n",
              "      <td>3.261244</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>319</td>\n",
              "      <td>FT911-2639</td>\n",
              "      <td>3.253312</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>319</td>\n",
              "      <td>FT934-11246</td>\n",
              "      <td>3.246675</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>319</td>\n",
              "      <td>LA052690-0075</td>\n",
              "      <td>3.231079</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-34979</td>\n",
              "      <td>3.217167</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-8077</td>\n",
              "      <td>3.204404</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-46058</td>\n",
              "      <td>3.184607</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>319</td>\n",
              "      <td>LA092890-0020</td>\n",
              "      <td>3.107272</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-67889</td>\n",
              "      <td>3.104928</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940921-0-00129</td>\n",
              "      <td>3.091989</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>319</td>\n",
              "      <td>FT943-8129</td>\n",
              "      <td>3.060746</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-1348</td>\n",
              "      <td>3.030407</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6422</td>\n",
              "      <td>3.016642</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6461</td>\n",
              "      <td>3.009335</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-8071</td>\n",
              "      <td>2.984728</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940525-2-00117</td>\n",
              "      <td>2.954475</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-59642</td>\n",
              "      <td>2.939045</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>319</td>\n",
              "      <td>LA080990-0248</td>\n",
              "      <td>2.926170</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-40284</td>\n",
              "      <td>2.914830</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>319</td>\n",
              "      <td>FT943-13268</td>\n",
              "      <td>2.888989</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-10410</td>\n",
              "      <td>2.884844</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20430</td>\n",
              "      <td>11.516721</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-21227</td>\n",
              "      <td>11.320892</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-49462</td>\n",
              "      <td>11.263755</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-47359</td>\n",
              "      <td>11.146114</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20471</td>\n",
              "      <td>11.089394</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-61780</td>\n",
              "      <td>10.981835</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20427</td>\n",
              "      <td>10.802876</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>320</td>\n",
              "      <td>FT933-8271</td>\n",
              "      <td>10.627179</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00016</td>\n",
              "      <td>10.445180</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-22928</td>\n",
              "      <td>10.350405</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>320</td>\n",
              "      <td>FR941104-2-00033</td>\n",
              "      <td>9.312199</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00021</td>\n",
              "      <td>9.046291</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-12066</td>\n",
              "      <td>8.656369</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-33968</td>\n",
              "      <td>8.336850</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-11935</td>\n",
              "      <td>8.191200</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>320</td>\n",
              "      <td>FT922-7917</td>\n",
              "      <td>8.171827</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940419-2-00016</td>\n",
              "      <td>7.334212</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00015</td>\n",
              "      <td>7.294864</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>320</td>\n",
              "      <td>LA102990-0070</td>\n",
              "      <td>6.734529</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>320</td>\n",
              "      <td>FT924-12375</td>\n",
              "      <td>6.433303</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-44604</td>\n",
              "      <td>6.347019</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>320</td>\n",
              "      <td>FT923-6172</td>\n",
              "      <td>6.285128</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>320</td>\n",
              "      <td>FT941-7241</td>\n",
              "      <td>6.229041</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>320</td>\n",
              "      <td>LA082190-0066</td>\n",
              "      <td>6.207445</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>320</td>\n",
              "      <td>FT944-14951</td>\n",
              "      <td>6.165612</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>320</td>\n",
              "      <td>LA111689-0186</td>\n",
              "      <td>6.101083</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20428</td>\n",
              "      <td>6.053951</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20429</td>\n",
              "      <td>5.994840</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>319</td>\n",
              "      <td>FT931-9555</td>\n",
              "      <td>3.034660</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6430</td>\n",
              "      <td>2.894382</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-12047</td>\n",
              "      <td>7.897239</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940216-0-00077</td>\n",
              "      <td>2.947042</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>320</td>\n",
              "      <td>FT944-17646</td>\n",
              "      <td>9.173340</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    queryid              name      score  rank  rel\n",
              "0       319     LA051690-0087   3.465312     1    0\n",
              "1       319        FT934-5009   3.391935     2    0\n",
              "2       319       FT933-13604   3.388628     3    0\n",
              "3       319  FR940921-0-00153   3.327169     4    0\n",
              "4       319       FT924-15359   3.310323     5    0\n",
              "5       319     LA121689-0080   3.269254     6    0\n",
              "6       319        FT924-3293   3.261244     7    0\n",
              "7       319        FT911-2639   3.253312     8    0\n",
              "8       319       FT934-11246   3.246675     9    0\n",
              "9       319     LA052690-0075   3.231079    10    0\n",
              "10      319       FBIS4-34979   3.217167    11    0\n",
              "11      319        FT922-8077   3.204404    12    0\n",
              "12      319       FBIS4-46058   3.184607    13    0\n",
              "13      319     LA092890-0020   3.107272    14    0\n",
              "14      319       FBIS4-67889   3.104928    15    0\n",
              "15      319  FR940921-0-00129   3.091989    16    0\n",
              "16      319        FT943-8129   3.060746    17    0\n",
              "17      319        FT923-1348   3.030407    19    0\n",
              "18      319        FT923-6422   3.016642    20    0\n",
              "19      319        FT923-6461   3.009335    21    0\n",
              "20      319        FT922-8071   2.984728    22    0\n",
              "21      319  FR940525-2-00117   2.954475    23    0\n",
              "22      319       FBIS3-59642   2.939045    25    0\n",
              "23      319     LA080990-0248   2.926170    26    0\n",
              "24      319       FBIS4-40284   2.914830    27    0\n",
              "25      319       FT943-13268   2.888989    29    0\n",
              "26      319       FT922-10410   2.884844    30    0\n",
              "27      320       FBIS4-20430  11.516721     1    0\n",
              "28      320       FBIS3-21227  11.320892     2    0\n",
              "29      320       FBIS4-49462  11.263755     3    0\n",
              "30      320       FBIS3-47359  11.146114     4    0\n",
              "31      320       FBIS4-20471  11.089394     5    0\n",
              "32      320       FBIS4-61780  10.981835     6    0\n",
              "33      320       FBIS4-20427  10.802876     7    0\n",
              "34      320        FT933-8271  10.627179     8    0\n",
              "35      320  FR940705-0-00016  10.445180     9    0\n",
              "36      320       FBIS4-22928  10.350405    10    0\n",
              "37      320  FR941104-2-00033   9.312199    11    0\n",
              "38      320  FR940705-0-00021   9.046291    13    0\n",
              "39      320       FT934-12066   8.656369    14    0\n",
              "40      320       FBIS3-33968   8.336850    15    0\n",
              "41      320       FT934-11935   8.191200    16    0\n",
              "42      320        FT922-7917   8.171827    17    0\n",
              "43      320  FR940419-2-00016   7.334212    19    0\n",
              "44      320  FR940705-0-00015   7.294864    20    0\n",
              "45      320     LA102990-0070   6.734529    21    0\n",
              "46      320       FT924-12375   6.433303    22    0\n",
              "47      320       FBIS4-44604   6.347019    23    0\n",
              "48      320        FT923-6172   6.285128    24    0\n",
              "49      320        FT941-7241   6.229041    25    0\n",
              "50      320     LA082190-0066   6.207445    26    0\n",
              "51      320       FT944-14951   6.165612    27    0\n",
              "52      320     LA111689-0186   6.101083    28    0\n",
              "53      320       FBIS4-20428   6.053951    29    0\n",
              "54      320       FBIS4-20429   5.994840    30    0\n",
              "55      319        FT931-9555   3.034660    18    0\n",
              "56      319        FT923-6430   2.894382    28    0\n",
              "57      320       FT934-12047   7.897239    18    0\n",
              "58      319  FR940216-0-00077   2.947042    24    0\n",
              "59      320       FT944-17646   9.173340    12    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ93Q97jsea",
        "colab_type": "code",
        "outputId": "0bea033a-9059-4348-811b-bdc6c5c97910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "monet_rels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "      <th>rel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-67889</td>\n",
              "      <td>8.441765</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>320</td>\n",
              "      <td>FT922-7917</td>\n",
              "      <td>18.816327</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>320</td>\n",
              "      <td>FT941-7241</td>\n",
              "      <td>14.342897</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20471</td>\n",
              "      <td>37.193072</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20427</td>\n",
              "      <td>36.714506</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-61780</td>\n",
              "      <td>34.839512</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00016</td>\n",
              "      <td>34.380059</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-22928</td>\n",
              "      <td>33.026922</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00021</td>\n",
              "      <td>32.304624</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-21227</td>\n",
              "      <td>31.853583</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>320</td>\n",
              "      <td>FR941104-2-00033</td>\n",
              "      <td>29.779604</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940705-0-00015</td>\n",
              "      <td>28.613698</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20430</td>\n",
              "      <td>26.518231</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-49462</td>\n",
              "      <td>25.935755</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-44604</td>\n",
              "      <td>25.876672</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-47359</td>\n",
              "      <td>25.664875</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>320</td>\n",
              "      <td>LA111689-0186</td>\n",
              "      <td>24.686549</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20428</td>\n",
              "      <td>24.542592</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>320</td>\n",
              "      <td>FT933-8271</td>\n",
              "      <td>24.469983</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>320</td>\n",
              "      <td>LA082190-0066</td>\n",
              "      <td>23.834774</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS4-20429</td>\n",
              "      <td>22.688370</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>320</td>\n",
              "      <td>FR940419-2-00016</td>\n",
              "      <td>21.813279</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>320</td>\n",
              "      <td>FT944-17646</td>\n",
              "      <td>21.122396</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>320</td>\n",
              "      <td>LA102990-0070</td>\n",
              "      <td>20.732091</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-12066</td>\n",
              "      <td>19.932026</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-33968</td>\n",
              "      <td>19.196306</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-11935</td>\n",
              "      <td>18.860935</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>320</td>\n",
              "      <td>FT934-12047</td>\n",
              "      <td>18.184065</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>320</td>\n",
              "      <td>FT924-12375</td>\n",
              "      <td>14.813227</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>320</td>\n",
              "      <td>FT923-6172</td>\n",
              "      <td>14.472042</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>320</td>\n",
              "      <td>FT944-14951</td>\n",
              "      <td>14.196847</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>319</td>\n",
              "      <td>FT934-5009</td>\n",
              "      <td>8.771522</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>319</td>\n",
              "      <td>FT933-13604</td>\n",
              "      <td>8.499482</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-34979</td>\n",
              "      <td>8.379140</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>319</td>\n",
              "      <td>LA121689-0080</td>\n",
              "      <td>8.368155</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940216-0-00077</td>\n",
              "      <td>8.324289</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>319</td>\n",
              "      <td>FT924-15359</td>\n",
              "      <td>8.310322</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940921-0-00129</td>\n",
              "      <td>8.279376</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>319</td>\n",
              "      <td>LA051690-0087</td>\n",
              "      <td>7.979175</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940921-0-00153</td>\n",
              "      <td>7.866096</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>319</td>\n",
              "      <td>FT924-3293</td>\n",
              "      <td>7.509293</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>319</td>\n",
              "      <td>FT911-2639</td>\n",
              "      <td>7.491027</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>319</td>\n",
              "      <td>FT934-11246</td>\n",
              "      <td>7.475745</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>319</td>\n",
              "      <td>LA052690-0075</td>\n",
              "      <td>7.439835</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-8077</td>\n",
              "      <td>7.378413</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-59642</td>\n",
              "      <td>7.342361</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-46058</td>\n",
              "      <td>7.332829</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>319</td>\n",
              "      <td>LA080990-0248</td>\n",
              "      <td>7.207319</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>319</td>\n",
              "      <td>LA092890-0020</td>\n",
              "      <td>7.154758</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>319</td>\n",
              "      <td>FT943-13268</td>\n",
              "      <td>7.081366</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>319</td>\n",
              "      <td>FT943-8129</td>\n",
              "      <td>7.047628</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>319</td>\n",
              "      <td>FT931-9555</td>\n",
              "      <td>6.987564</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-1348</td>\n",
              "      <td>6.977769</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6422</td>\n",
              "      <td>6.946076</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6461</td>\n",
              "      <td>6.929251</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-8071</td>\n",
              "      <td>6.872589</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940525-2-00117</td>\n",
              "      <td>6.802929</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-40284</td>\n",
              "      <td>6.711645</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>319</td>\n",
              "      <td>FT923-6430</td>\n",
              "      <td>6.664562</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>319</td>\n",
              "      <td>FT922-10410</td>\n",
              "      <td>6.642599</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    queryid              name      score  rank  rel\n",
              "0       319       FBIS4-67889   8.441765     3    1\n",
              "1       320        FT922-7917  18.816327    25    1\n",
              "2       320        FT941-7241  14.342897    29    1\n",
              "3       320       FBIS4-20471  37.193072     1    0\n",
              "4       320       FBIS4-20427  36.714506     2    0\n",
              "5       320       FBIS4-61780  34.839512     3    0\n",
              "6       320  FR940705-0-00016  34.380059     4    0\n",
              "7       320       FBIS4-22928  33.026922     5    0\n",
              "8       320  FR940705-0-00021  32.304624     6    0\n",
              "9       320       FBIS3-21227  31.853583     7    0\n",
              "10      320  FR941104-2-00033  29.779604     8    0\n",
              "11      320  FR940705-0-00015  28.613698     9    0\n",
              "12      320       FBIS4-20430  26.518231    10    0\n",
              "13      320       FBIS4-49462  25.935755    11    0\n",
              "14      320       FBIS4-44604  25.876672    12    0\n",
              "15      320       FBIS3-47359  25.664875    13    0\n",
              "16      320     LA111689-0186  24.686549    14    0\n",
              "17      320       FBIS4-20428  24.542592    15    0\n",
              "18      320        FT933-8271  24.469983    16    0\n",
              "19      320     LA082190-0066  23.834774    17    0\n",
              "20      320       FBIS4-20429  22.688370    18    0\n",
              "21      320  FR940419-2-00016  21.813279    19    0\n",
              "22      320       FT944-17646  21.122396    20    0\n",
              "23      320     LA102990-0070  20.732091    21    0\n",
              "24      320       FT934-12066  19.932026    22    0\n",
              "25      320       FBIS3-33968  19.196306    23    0\n",
              "26      320       FT934-11935  18.860935    24    0\n",
              "27      320       FT934-12047  18.184065    26    0\n",
              "28      320       FT924-12375  14.813227    27    0\n",
              "29      320        FT923-6172  14.472042    28    0\n",
              "30      320       FT944-14951  14.196847    30    0\n",
              "31      319        FT934-5009   8.771522     1    0\n",
              "32      319       FT933-13604   8.499482     2    0\n",
              "33      319       FBIS4-34979   8.379140     4    0\n",
              "34      319     LA121689-0080   8.368155     5    0\n",
              "35      319  FR940216-0-00077   8.324289     6    0\n",
              "36      319       FT924-15359   8.310322     7    0\n",
              "37      319  FR940921-0-00129   8.279376     8    0\n",
              "38      319     LA051690-0087   7.979175     9    0\n",
              "39      319  FR940921-0-00153   7.866096    10    0\n",
              "40      319        FT924-3293   7.509293    11    0\n",
              "41      319        FT911-2639   7.491027    12    0\n",
              "42      319       FT934-11246   7.475745    13    0\n",
              "43      319     LA052690-0075   7.439835    14    0\n",
              "44      319        FT922-8077   7.378413    15    0\n",
              "45      319       FBIS3-59642   7.342361    16    0\n",
              "46      319       FBIS4-46058   7.332829    17    0\n",
              "47      319     LA080990-0248   7.207319    18    0\n",
              "48      319     LA092890-0020   7.154758    19    0\n",
              "49      319       FT943-13268   7.081366    20    0\n",
              "50      319        FT943-8129   7.047628    21    0\n",
              "51      319        FT931-9555   6.987564    22    0\n",
              "52      319        FT923-1348   6.977769    23    0\n",
              "53      319        FT923-6422   6.946076    24    0\n",
              "54      319        FT923-6461   6.929251    25    0\n",
              "55      319        FT922-8071   6.872589    26    0\n",
              "56      319  FR940525-2-00117   6.802929    27    0\n",
              "57      319       FBIS4-40284   6.711645    28    0\n",
              "58      319        FT923-6430   6.664562    29    0\n",
              "59      319       FT922-10410   6.642599    30    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDGp5RMXsywM",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation framework\n",
        "\n",
        "We can download the custom implementation of the evaluation metrics from our Github repository and import the `metrics.py` Python file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PGmoWnIso6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update download link to master branch when it is up to date\n",
        "!wget https://raw.githubusercontent.com/nnistelrooij/Information-Retrieval/evaluation/metrics.py\n",
        "\n",
        "import metrics\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWec5_RAEdcP",
        "colab_type": "text"
      },
      "source": [
        "### MAP and gMAP\n",
        "\n",
        "The performance of the retrieval models on the test collection can be evaluated with the Mean Average Precision (MAP). Another variant of this metric is the Geometric Mean Average Precision (gMAP), which places more emphasis on low performing queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91OXiTu8ty0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_test_collection(df, metric_func):\n",
        "  \"\"\"\n",
        "  Evaluates the ranked lists from a test collection \n",
        "  of a retrieval model using the specified `metric_func`.\n",
        "\n",
        "  Args:\n",
        "    df          = [DataFrame] pandas DataFrame that houses\n",
        "                              the output of a retrieval model\n",
        "                              (required columns: `queryid`, `rank`, `rel`)\n",
        "    metric_func = [function] a function that computes a score\n",
        "                             for a test collection; the function\n",
        "                             must only accept one argument, which is a\n",
        "                             nested collection of relevance judgements,\n",
        "                             e.g., [[1,1,0], [0,1,1], [1,0,0], ...]\n",
        "\n",
        "  Returns [int]:\n",
        "    Score from `metric_func`\n",
        "  \"\"\"\n",
        "  query_ids = pd.unique(df.queryid)\n",
        "  rels = []\n",
        "  for query_id in query_ids:\n",
        "    rel = df[df.queryid == query_id].sort_values(by=['rank']).rel.to_numpy()\n",
        "    rels.append(rel)\n",
        "  return metric_func(rels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu2R-ga_qbX3",
        "colab_type": "code",
        "outputId": "bff56b10-e71a-4577-9dcc-9d13ea378fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# We can either use MAP or gMAP here to evaluate the test collection\n",
        "duck_MAP = evaluate_test_collection(duck_rels, metrics.mean_average_precision)\n",
        "monet_MAP = evaluate_test_collection(monet_rels, metrics.mean_average_precision)\n",
        "print(\"Duck MAP:\", duck_MAP)\n",
        "print(\"monet MAP:\", monet_MAP)\n",
        "\n",
        "duck_gMAP = evaluate_test_collection(duck_rels, metrics.geometric_mean_average_precision)\n",
        "monet_gMAP = evaluate_test_collection(monet_rels, metrics.geometric_mean_average_precision)\n",
        "print(\"Duck gMAP:\", duck_gMAP)\n",
        "print(\"monet gMAP:\", monet_gMAP)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duck MAP: 0.0\n",
            "monet MAP: 0.007371647509578544\n",
            "Duck gMAP: 0.0\n",
            "monet gMAP: 0.006352763097919567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDmuTwwQEWHT",
        "colab_type": "text"
      },
      "source": [
        "### Kendall's $\\tau$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T2WnVVp7mUE",
        "colab_type": "text"
      },
      "source": [
        "We can also quantify to what extent ranked lists differ from each other after term proximity using Kendall's $\\tau$. The ranked lists must contain the same elements, i.e, output from the retrieval models should be from term proximity on top *k* documents or just the top *k* documents without term proximity. In the options of the `Retriever` functions we must set `num_docs` equal to `k` to ensure that the returned ranked lists contain the same documents, which is a requirement to compute Kendall's $\\tau$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ucpHEj3jxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_ranked_lists(df_A, df_B, query_id):\n",
        "  \"\"\"\n",
        "  Compute Kendall's tau for a specific query from the test collection.\n",
        "  Inputs should be from the output of `Retriever.retrieve_all()`.\n",
        "\n",
        "  Args:\n",
        "    df_A = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `queryid`, `rank`)\n",
        "    df_B = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `queryid`, `rank`)\n",
        "\n",
        "  Returns [tuple]:\n",
        "    Tuple of Kendall's tau and p-value\n",
        "  \"\"\"\n",
        "  ranked_doc_names_A = df_A[df_A.queryid == query_id].sort_values(by=['rank']).name.to_numpy()\n",
        "  ranked_doc_names_B = df_B[df_B.queryid == query_id].sort_values(by=['rank']).name.to_numpy()\n",
        "  return metrics.kendall_tau(ranked_doc_names_A, ranked_doc_names_B)\n",
        "\n",
        "def compare_all_ranked_lists(df_A, df_B):\n",
        "  \"\"\"\n",
        "  Compute Kendall's tau for all queries in a test collection.\n",
        "  Inputs should be from the output of `Retriever.retrieve_all()`.\n",
        "\n",
        "  Args:\n",
        "    df_A = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `queryid`, `rank`)\n",
        "    df_B = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `queryid`, `rank`)\n",
        "\n",
        "    Returns [[tuple]]:\n",
        "      List of tuples in the form (queryid, KendalltauResult)\n",
        "  \"\"\"\n",
        "  query_ids = pd.unique(df_A.queryid)\n",
        "  results = []\n",
        "  for query_id in query_ids:\n",
        "    result = compare_ranked_lists(monet_rels_no_tp, monet_rels, query_id)\n",
        "    results.append((query_id, result))\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTY6dg-rD1tM",
        "colab_type": "text"
      },
      "source": [
        "We already have a run of monet with term proximity `monet_rels`, and now we can also get a run without term proximity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEq630qt9a8V",
        "colab_type": "code",
        "outputId": "1ddc98c2-2521-4e06-9416-1915b0a7f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "monet_rels_no_tp = retriever.retrieve_all('queries_test.csv', 'qrels.csv', monet, con_query=False, tp=False, num_docs=30)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf ,queries.queryid ,queries.len FROM dict JOIN queries ON dict.term = queries.term) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qtermids.df ,qtermids.cf ,qtermids.queryid ,qtermids.len ,( ROW_NUMBER() OVER(PARTITION BY qtermids.queryid ,qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM terms AS qterms JOIN qtermids ON qterms.termid = qtermids.termid) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf ,qtermstfrows.queryid ,qtermstfrows.len FROM qtermstfrows WHERE qtermstfrows.row = 1) , kldsubscores AS (SELECT qtermstf.docid ,qtermstf.queryid ,( LOG(0.800000+tf*109623557.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,subscores.queryid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(PARTITION BY subscores.queryid ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid ,subscores.queryid) , topkdocs AS (SELECT topdocs.docid ,topdocs.queryid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , scores AS (SELECT topkdocs.docid ,topkdocs.queryid ,topkdocs.score ,( ROW_NUMBER() OVER(PARTITION BY topkdocs.queryid ORDER BY topkdocs.score DESC)) AS rank FROM topkdocs) , topndocs AS (SELECT scores.queryid ,scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 and 30) SELECT topndocs.queryid ,docs.name ,topndocs.score ,topndocs.rank ,COALESCE(qrels.rel, 0) AS rel FROM topndocs JOIN docs ON topndocs.docid = docs.docid LEFT JOIN qrels ON topndocs.queryid = qrels.queryid AND docs.name = qrels.name\n",
            "Query time: 0:00:00.497022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rWFeGai2oHw",
        "colab_type": "text"
      },
      "source": [
        "The Kendall's $\\tau$ can be computed for all queries in the test collection at once. We can also take the mean of it, but that probably is not very informative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utYCI2xk-A18",
        "colab_type": "code",
        "outputId": "fde13c3d-45c9-43c4-d7db-29662405cdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "results = compare_all_ranked_lists(monet_rels_no_tp, monet_rels)\n",
        "print(results)\n",
        "\n",
        "taus = [res[0] for _, res in results]\n",
        "mean_tau = np.mean(taus)\n",
        "print(\"Mean Kendall's tau:\", mean_tau)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(319, KendalltauResult(correlation=0.5448275862068965, pvalue=9.169593557192102e-06)), (320, KendalltauResult(correlation=0.020689655172413793, pvalue=0.8875122085953924))]\n",
            "Mean Kendall's tau: 0.2827586206896552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvz3VIpfEsLD",
        "colab_type": "text"
      },
      "source": [
        "We can also do ad hoc retrieval for a single query using `retriever.retrieve()` and compute the Kendall's tau for that query over two ranked lists. Again make sure to set `num_docs` equal to `k`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tuj7GbmBYO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_ranked_lists_ad_hoc(df_A, df_B):\n",
        "  \"\"\"\n",
        "  Compute Kendall's tau for two ranked lists.\n",
        "  Inputs should be from the output of `Retriever.retrieve()`.\n",
        "\n",
        "  Args:\n",
        "    df_A = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `docid`, `rank`)\n",
        "    df_B = [DataFrame] pandas DataFrame that houses\n",
        "                       the output of a retrieval model\n",
        "                       (required columns: `docid`, `rank`)\n",
        "\n",
        "  Returns [tuple]:\n",
        "    Tuple of Kendall's tau and p-value\n",
        "  \"\"\"\n",
        "  ranked_doc_names_A = df_A.sort_values(by=['rank']).docid.to_numpy()\n",
        "  ranked_doc_names_B = df_B.sort_values(by=['rank']).docid.to_numpy()\n",
        "  return metrics.kendall_tau(ranked_doc_names_A, ranked_doc_names_B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A16xNvJb8a60",
        "colab_type": "code",
        "outputId": "8746b34b-d886-425e-876f-dd0e3123f567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "query = ['new', 'york']\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='okapi', tp=False, num_docs=30)\n",
        "monet_scores_tp = retriever.retrieve(query, monet, pre_select='okapi', tp=True, num_docs=30)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qtermids.df ,( ROW_NUMBER() OVER(PARTITION BY qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM terms AS qterms JOIN qtermids ON qterms.termid = qtermids.termid) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid FROM qtermstf AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , okapisubscores AS (SELECT qtermstf.docid ,( LOG((528030.000000-df+0.5)/(df+0.5))*tf*(1.200000+1)/(tf+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM okapisubscores AS subscores GROUP BY subscores.docid) , topkdocs AS (SELECT topdocs.docid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , scores AS (SELECT topkdocs.docid ,topkdocs.score ,( ROW_NUMBER() OVER(ORDER BY topkdocs.score DESC)) AS rank FROM topkdocs) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 30\n",
            "Query time: 0:00:00.336926\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,( ROW_NUMBER() OVER(PARTITION BY qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , okapisubscores AS (SELECT qtermstf.docid ,( LOG((528030.000000-df+0.5)/(df+0.5))*tf*(1.200000+1)/(tf+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM okapisubscores AS subscores GROUP BY subscores.docid) , topkdocs AS (SELECT topdocs.docid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN topkdocs ON qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT topkdocs.docid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 30\n",
            "Query time: 0:00:00.348558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voz5FBF3FRgV",
        "colab_type": "code",
        "outputId": "33e7be7f-5559-41eb-ce74-db40dd1d6f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "monet_ny_tau, monet_ny_pval = compare_ranked_lists_ad_hoc(monet_scores, monet_scores_tp)\n",
        "print(\"Tau:\", monet_ny_tau, \"p-value:\", monet_ny_pval)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tau: 0.28735632183908044 p-value: 0.026031023086731955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uvmhehsUxY2",
        "colab_type": "text"
      },
      "source": [
        "## Options\n",
        "\n",
        "Now we will explain how to use this complicated `retrieve()` function by setting a number of specific options on or off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRFX-M6HQPlM",
        "colab_type": "text"
      },
      "source": [
        "### All options\n",
        "\n",
        "Let's start with the default options. The query will be (`query=`)*new york* and it will be executed for both databases (`db=DuckDB` and `db=MonetDBLite`).\n",
        "\n",
        "First, the top (`k=`)30 documents are retrieved using the Kullback-Leibler Divergence (`pre_select='kld'`) retrieval model with conjunctive queries (`con_query=True`) and a $\\mu$ of 0.8 (`mu=0.8`). Then, these 30 documents are scored again with term proximity weighting (`tp=True`) based on a modified version of the [Rasolofo algorithm](https://www.researchgate.net/publication/225174089_Term_Proximity_Scoring_for_Keyword-Based_Retrieval_Systems), with a $k1$ of 1.2 (`k1=1.2`), a $b$ of 0.75 (`b=0.75`), and a maximum distance of 5 (`max_span=5`) between query terms. The scores obtained from KLD and Rasolofo are summed (`sum=True`) to arrive at the final score and ranking. Of this final ranking, 20 documents are retrieved (`num_docs=20`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgVPDEmB4Igm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = ['new', 'york']\n",
        "\n",
        "print(\"DuckDB with all options\")\n",
        "duck_scores = retriever.retrieve(query, duck)\n",
        "\n",
        "print(\"\\nMonetDBLite with all options\")\n",
        "monet_scores = retriever.retrieve(query, monet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_gH2BcUrG1",
        "colab_type": "text"
      },
      "source": [
        "DuckDB was very slow compared to MonetDBLite (approximately a factor of 35). The query that both databases execute is identical, so the time difference is purely DuckDB's shortcoming. Furthermore, the actual scores from DuckDB are different than from MonetDBLite. However, the ranking, surprisingly, is identical between the two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nDcip3n5UyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gn2sGid5XyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlRmarebV0X8",
        "colab_type": "text"
      },
      "source": [
        "### No term proximity weighting\n",
        "\n",
        "If you only want to rank the documents based on Okapi BM25, then run the following code. All the other options, where applicable, are still the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK93im7CVw45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with only Okapi BM25\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='okapi', tp=False)\n",
        "\n",
        "print(\"\\nMonetDBLite with  only Okapi BM25\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='okapi', tp=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6XrXrmW4lJ",
        "colab_type": "text"
      },
      "source": [
        "The difference in time between DuckDB and MonetDBLite is now much smaller (a factor of about 10), but the scores are still different, whereas the ranking is again identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TV9ClY3Wk37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRqb0iFWlx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VLDFS-AXI1w",
        "colab_type": "text"
      },
      "source": [
        "### Only term proximity weighting\n",
        "\n",
        "If you do not want to pre-select `k` documents, before computing the Rasolofo score, then run the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzTTWCIXbOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with only Rasolofo\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none')\n",
        "\n",
        "print(\"\\nMonetDBLite with only Rasolofo\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzHjlAFSX327",
        "colab_type": "text"
      },
      "source": [
        "The factor in the time difference is approximately 10. The execution time for MonetDBLite is more than previously. This makes sense; the algorithm needs to find the close query term pairs in all the documents instead of only the top 30 documents. This operation has a super-linear running time, so it takes MonetDBLite longer to produce the output.\n",
        "\n",
        "The scores are again different, but now the ranking is also different. So DuckDB does not work for the given query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N3a41GsXl-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWj_nAS3Xn3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezy8UUQ1YrhR",
        "colab_type": "text"
      },
      "source": [
        "### Bigger term pair radius\n",
        "\n",
        "If the Rasolofo algorithm retrieves too few documents with the default parameters, the span of a term pair can be expanded to include more documents. To do that, run the below code with the query *wizard hat*.\n",
        "\n",
        "It is slightly slower than the default span with MonetDBLite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RdGwDm3Y7tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = ['wizard', 'hat']\n",
        "\n",
        "print(\"DuckDB with default term pair span\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none')\n",
        "\n",
        "print(\"\\nMonetDBLite with default term pair span\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEYnzs4naAgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ehWfvUzaBca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQhJyibdZI9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with bigger term pair span\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none', max_span=20)\n",
        "\n",
        "print(\"\\nMonetDBLite with bigger term pair span\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none', max_span=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MA5wns7aO2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shbxRlsWaPjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LaK3trkapWz",
        "colab_type": "text"
      },
      "source": [
        "### Only TP scores\n",
        "\n",
        "If you want that the final score is only the Rasolofo score, then set `sum=False`. So not the sum of the pre-selection score and the Rasolofo score as final score, but only the Rasolofo score. If the Rasolofo algorithm could not score a document that was retrieved by the pre-selection retrieval model, then that document will not be included in the ranking. So do be aware of that when setting this option!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P31m40X0bmgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with summed scores\")\n",
        "duck_scores = retriever.retrieve(query, duck)\n",
        "\n",
        "print(\"\\nMonetDBLite with summed scores\")\n",
        "monet_scores = retriever.retrieve(query, monet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDIoEXrfb52u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2zsci_Xb6sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCNajxI1b9op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with Rasolofo scores\")\n",
        "duck_scores = retriever.retrieve(query, duck, sum=False)\n",
        "\n",
        "print(\"\\nMonetDBLite with Rasolofo scores\")\n",
        "monet_scores = retriever.retrieve(query, monet, sum=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ZkxekJcC9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnL9g2NscENC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxId-FH-cQ43",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "As seen by the many options, there are endless opportunities for research and evaluation. And we haven't even talked about combining options, disjunctive queries, or hyper-parameters, yet.\n",
        "\n",
        "Our question right now is basically: why is DuckDB so slow and why does DuckDB give incorrect and unintuitive results. Analyzing the runtime of MonetDBLite was much more straightforward than for DuckDB. Is there still some hope for DuckDB, maybe in the future? Or should we only focus on MonetDBLite and maybe implement a second term proximity retrieval model, instead of comparing the two databases?"
      ]
    }
  ]
}