{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwoFunction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Lr4ekZEjU0",
        "colab_type": "text"
      },
      "source": [
        "# Term Proximity Retrieval Model in SQL using DuckDB and MonetDBLite\n",
        "\n",
        "This notebook is a work in progress for the Information Retrieval course research project. A number of retrievel models are implemented in SQL queries that can be run with two database systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzHGaGElGGZ8",
        "colab_type": "text"
      },
      "source": [
        "## Index\n",
        "\n",
        "A preliminary index of the Robust04 data set was first [downloaded from Jimmy Lin's Dropbox](https://www.dropbox.com/s/mdoly9sjdalh44x/lucene-index.robust04.pos%2Bdocvectors%2Brawdocs.tar.gz). Then the [OldDog](https://github.com/Chriskamphuis/olddog) code from Chris Kamphuis and Arjen de Vries was modified to work with more than one leaf. Their code was further modified to store the collection frequency of each term and the term frequency of each term in each document. The modified code was run, which resulted in three CSV tables. \n",
        "\n",
        "The *dict* table houses termid, term, document frequency, and collection frequency data. The *docs* table houses name, docid, and document length information. And finally, the *terms* table houses the termid, docid, position, and term frequency data.\n",
        "\n",
        "These three tables are put in an archive, so that they can be easily [downloaded from Dropbox](https://www.dropbox.com/s/5qwq3gn6rto98sd/Robust04%2Bpos%2Btf%2Bcf.rar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkE-y3cGS1MO",
        "colab_type": "code",
        "outputId": "55483332-c45f-4087-8a9e-7508326fca3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "!wget -O Robust04.rar https://dl.dropboxusercontent.com/s/kzu6yuxt2d1wzww/Robust04Tables.rar?dl=0\n",
        "!unrar e -o+ Robust04.rar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-09 15:37:33--  https://dl.dropboxusercontent.com/s/kzu6yuxt2d1wzww/Robust04Tables.rar?dl=0\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 724523928 (691M) [application/rar]\n",
            "Saving to: ‘Robust04.rar’\n",
            "\n",
            "Robust04.rar        100%[===================>] 690.96M  6.03MB/s    in 93s     \n",
            "\n",
            "2019-12-09 15:39:07 (7.45 MB/s) - ‘Robust04.rar’ saved [724523928/724523928]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Robust04.rar\n",
            "\n",
            "Extracting  dict.csv                                                     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  docs.csv                                                     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  terms.csv                                                    \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  qrels.csv                                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XbFCaWPzLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LXIae-4JC7G",
        "colab_type": "text"
      },
      "source": [
        "## Databases\n",
        "\n",
        "Both DuckDB and MonetDBLite will be used to test the differences between them on a number of dimensions, during the evaluation phase of the research.\n",
        "\n",
        "Google Colab does not pre-install these packages, so that is why we need to do `pip install`. This takes about 5 minutes for DuckDB, so please already run the next cell, before reading on.\n",
        "\n",
        "Here, we have made two classes that do the necessary tasks that we need the databases to do.\n",
        "\n",
        "MonetDB cannot be used, as it requires an external Java MonetDB server, and the project was to be made with the Python APIs. That leaves us with MonetDBLite. For some reason, they have taken out the Python DB API for MonetDBLite (the `Cursor` class and `cursor.execute()` function). We could enable it by modifying the source code, but the program also needs to work for other people on other computers. So we just stuck to the Simple API of MonetDBLite. Another titbit, MonetDBLite cannot be initialized in the memory. If you go over some memory bandwith threshold, the whole database stops working. So, MonetDBLite needs to be initialized in storage. The performance difference is not that big on Google Colab, but it did matter on a local runtime.\n",
        "\n",
        "When initializing the database objects, the index tables are automatically added. So you only have to initialize them once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOnPbiYTEph",
        "colab_type": "code",
        "outputId": "282f3392-954e-4caf-db25-0f298fe73fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install duckdb\n",
        "import duckdb\n",
        "\n",
        "class DuckDB(object):\n",
        "  \"\"\"\n",
        "  Class that houses all the DuckDB functionalities.\n",
        "\n",
        "  Attributes:\n",
        "    c         = [Cursor] database cursor of DuckDB\n",
        "    C         = [int] number of indexed terms\n",
        "    N         = [int] number of indexed documents\n",
        "    avgdl     = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database=':memory:',\n",
        "               dict='dict.csv',\n",
        "               docs='docs.csv',\n",
        "               terms='terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes DuckDB database with index and statistics.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    # initialize database\n",
        "    con = duckdb.connect(database)\n",
        "    self.c = con.cursor()\n",
        "\n",
        "    # copy dictionary CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                                    \",term   VARCHAR \"\n",
        "                                    \",df     INTEGER \"\n",
        "                                    \",cf     INTEGER)\")\n",
        "    self.c.execute(\"COPY dict \"\n",
        "                   \"FROM '\" + dict + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy documents CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE docs(name  VARCHAR \"\n",
        "                                    \",docid INTEGER \"\n",
        "                                    \",len   INTEGER \"\n",
        "                                    \",temp  INTEGER)\")\n",
        "    self.c.execute(\"COPY docs \"\n",
        "                   \"FROM '\" + docs + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy terms CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                                     \",docid  INTEGER \"\n",
        "                                     \",pos    INTEGER \"\n",
        "                                     \",tf     INTEGER)\")\n",
        "    self.c.execute(\"COPY terms \"\n",
        "                   \"FROM '\" + terms + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in DuckDB database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    # convert search query in to SQL query\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    # make new or replace old query table\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS query\")\n",
        "    self.c.execute(\"CREATE TABLE query(term VARCHAR)\")\n",
        "    self.c.execute(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    # bookkeeping\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def make_queries(self, queries, qrels):\n",
        "    \"\"\"\n",
        "    Makes queries and qrels tables in DuckDB database filled with\n",
        "    queryid, term pairs and queryid, docid relevance, respectively.\n",
        "\n",
        "    Args:\n",
        "      queries = [str] filename for search queries CSV\n",
        "      qrels   = [str] filename for relevance judgements CSV\n",
        "    \"\"\"\n",
        "    # copy queries CSV into DuckDB database\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS queries\")\n",
        "    self.c.execute(\"CREATE TABLE queries(queryid INTEGER \"\n",
        "                                       \",term    VARCHAR \"\n",
        "                                       \",len     INTEGER)\")\n",
        "    self.c.execute(\"COPY queries \"\n",
        "                   \"FROM '\" + queries + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy relevance judgements CSV into DuckDB database\n",
        "    self.c.execute(\"DROP TABLE IF EXISTS qrels\")\n",
        "    self.c.execute(\"CREATE TABLE qrels(queryid INTEGER \"\n",
        "                                     \",name    VARCHAR \"\n",
        "                                     \",rel     INTEGER)\")\n",
        "    self.c.execute(\"COPY qrels \"\n",
        "                   \"FROM '\" + qrels + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on DuckDB database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by DuckDB\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = self.c.execute(query)\n",
        "    return out.fetchdf()\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = self.c.execute(\"SELECT SUM(dict.cf) \"\n",
        "                       \"FROM dict\")\n",
        "    return C.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = self.c.execute(\"SELECT COUNT(*) \"\n",
        "                       \"FROM docs\")\n",
        "    return N.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = self.c.execute(\"SELECT AVG(docs.len) \"\n",
        "                           \"FROM docs\")\n",
        "    return avgdl.fetchdf().iloc[0, 0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting duckdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/45/37215c3e2fc9c5b94e379a0b3b85a388107d3d626cde8cfacea377ba1696/duckdb-0.1.1.tar.gz (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from duckdb) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from duckdb) (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23->duckdb) (1.12.0)\n",
            "Building wheels for collected packages: duckdb\n",
            "  Building wheel for duckdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for duckdb: filename=duckdb-0.1.1-cp36-cp36m-linux_x86_64.whl size=1947910 sha256=c914095bee3fc31f476e22566cb70a0f1771ff74a37495de851a2699abd81230\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/2e/81/8061e62cf80a0ea73a4657d5807c46a93105440af5921e828c\n",
            "Successfully built duckdb\n",
            "Installing collected packages: duckdb\n",
            "Successfully installed duckdb-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YojwuWrTd6N",
        "colab_type": "code",
        "outputId": "15de1a57-3736-4086-d70e-f2903f6390fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip install monetdblite\n",
        "import monetdblite as m\n",
        "\n",
        "class MonetDBLite(object):\n",
        "  \"\"\" \n",
        "  Class that houses all the MonetDBLite functionalities. \n",
        "\n",
        "  Attributes:\n",
        "    C     = [int] number of indexed terms\n",
        "    N     = [int] number of indexed documents\n",
        "    avgdl = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database='/tmp/MonetDBLite Database',\n",
        "               dict='dict.csv',\n",
        "               docs='docs.csv',\n",
        "               terms='terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes MonetDBLite database with index.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    # MonetDBLite expects an absolute path\n",
        "    dict = os.path.join('/content', dict)\n",
        "    docs = os.path.join('/content', docs)\n",
        "    terms = os.path.join('/content', terms)\n",
        "\n",
        "    # initialize database\n",
        "    m.init(database)\n",
        "\n",
        "    # copy dictionary CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                           \",term   VARCHAR(99) \"\n",
        "                           \",df     INTEGER \"\n",
        "                           \",cf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO dict \"\n",
        "          \"FROM '\" + dict + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy documents CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE docs(name  VARCHAR(99) \"\n",
        "                           \",docid INTEGER \"\n",
        "                           \",len   INTEGER \"\n",
        "                           \",temp  INTEGER)\") \n",
        "    m.sql(\"COPY INTO docs \"\n",
        "          \"FROM '\" + docs + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy terms CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                            \",docid  INTEGER \"\n",
        "                            \",pos    INTEGER \"\n",
        "                            \",tf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO terms \"\n",
        "          \"FROM '\" + terms + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in MonetDBLite database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    # convert search query in to SQL query\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    # make new or replace old query table\n",
        "    m.sql(\"DROP TABLE IF EXISTS query\")\n",
        "    m.sql(\"CREATE TABLE query(term VARCHAR(99))\")\n",
        "    m.sql(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    # bookkeeping\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def make_queries(self, queries, qrels):\n",
        "    \"\"\"\n",
        "    Makes queries and qrels tables in MonetDBLite database filled with\n",
        "    queryid, term pairs and queryid, docid relevance, respectively.\n",
        "\n",
        "    Args:\n",
        "      queries = [str] filename for search queries CSV\n",
        "      qrels   = [str] filename for relevance judgements CSV\n",
        "    \"\"\"\n",
        "    # MonetDBLite expects an absolute path\n",
        "    queries = os.path.join('/content', queries)\n",
        "    qrels = os.path.join('/content', qrels)\n",
        "\n",
        "    # copy queries CSV into MonetDBLite database\n",
        "    m.sql(\"DROP TABLE IF EXISTS queries\")\n",
        "    m.sql(\"CREATE TABLE queries(queryid INTEGER \"\n",
        "                              \",term    VARCHAR(99) \"\n",
        "                              \",len     INTEGER)\")\n",
        "    m.sql(\"COPY INTO queries \"\n",
        "          \"FROM '\" + queries + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy relevance judgements CSV into MonetDBLite database\n",
        "    m.sql(\"DROP TABLE IF EXISTS qrels\")\n",
        "    m.sql(\"CREATE TABLE qrels(queryid INTEGER \"\n",
        "                            \",name    VARCHAR(99) \"\n",
        "                            \",rel     INTEGER)\")\n",
        "    m.sql(\"COPY INTO qrels \"\n",
        "          \"FROM '\" + qrels + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on MonetDBLite database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by MonetDBLite\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = m.sql(query)\n",
        "    return pd.DataFrame.from_dict(out)\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = m.sql(\"SELECT SUM(dict.cf) \"\n",
        "              \"FROM dict\")\n",
        "    return pd.DataFrame.from_dict(C).iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = m.sql(\"SELECT COUNT(*) \"\n",
        "              \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(N).iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = m.sql(\"SELECT AVG(docs.len) \"\n",
        "                  \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(avgdl).iloc[0, 0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting monetdblite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/6a/d49c0b03c62c81098ecd42c6e2ed037979355d00797326a6acd2090f4822/monetdblite-0.6.3-cp36-cp36m-manylinux1_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.20->monetdblite) (1.12.0)\n",
            "Installing collected packages: monetdblite\n",
            "Successfully installed monetdblite-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3r4KeAvMEh7",
        "colab_type": "text"
      },
      "source": [
        "## Retriever\n",
        "\n",
        "The next class houses the function for retrieving the relevant documents given a number of options, `retrieve()`. The private methods (starting with an underscore) could really use some help. So please only use the `retrieve()` function further into the file. Perhaps we will clean up the mess later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p2vSKIYU9H4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class Retriever(object):\n",
        "  \"\"\" Class to do document retrieval with term proximity using databases. \"\"\"     \n",
        "  def retrieve(self,\n",
        "               query, \n",
        "               db,\n",
        "               con_query=True, \n",
        "               pre_select='kld', \n",
        "               tp=True,\n",
        "               k=30,\n",
        "               sum=True,\n",
        "               mu=0.8, # totally not sure about this hyper-parameter\n",
        "               k1=1.2,\n",
        "               b=0.75,\n",
        "               num_docs=20,\n",
        "               max_span=5):\n",
        "    \"\"\"\n",
        "    Function that retreives documents with a Retrieval Status Value (RSV)\n",
        "    based on term-proximity (TP) weighting, Okapi BM25 or Kullback-Leibler\n",
        "    Divergence. When opting for TP, k documents can be pre-selected with\n",
        "    the Okapi BM25 or Kullback-Leibler Divergence retrieval models.\n",
        "\n",
        "    Args:\n",
        "      query      = [[str]] the tokenized and normalized query\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      tp         = [bool] whether to do the term proximity at all\n",
        "      k          = [int] maximum number of documents to retrieve with\n",
        "                         the pre-selection retrieval model\n",
        "      sum        = [bool] whether to sum the pre-selection and term \n",
        "                          proximity scores for the final score\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "      max_span   = [int] maximum distance, in number of terms, for a term\n",
        "                         pair to be included in the term proximity score\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output, where the columns are the document id,\n",
        "      the score of the document given the query, and the rank of the\n",
        "      document given the query.\n",
        "    \"\"\"\n",
        "    # add the search query as a table to the database\n",
        "    db.make_query(*query)\n",
        "\n",
        "    # determine the SQL query\n",
        "    sql = (self._qterms(pre_select, tp) +\n",
        "           self._qtermstf(pre_select, tp) +\n",
        "           self._condocs(db, con_query, tp) +\n",
        "           self._pre_select_subscores(db, con_query, pre_select, mu, k1, b) +\n",
        "           self._topkdocs(pre_select, k) + \n",
        "           self._pairs(con_query, pre_select, tp, max_span) +\n",
        "           self._tpscores(db, tp, k1, b) +\n",
        "           self._scores(pre_select, tp, sum, num_docs))\n",
        "    print('Query: {}'.format(sql))\n",
        "    \n",
        "    # get the elapsed time and the results after executing the SQL query\n",
        "    time = datetime.now()\n",
        "    out = db.execute_query(sql)\n",
        "    time_delta = datetime.now() - time\n",
        "    print('Query time: {}'.format(time_delta))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def retrieve_all(self,\n",
        "                   queries,\n",
        "                   qrels,\n",
        "                   db,\n",
        "                   con_query=True, \n",
        "                   pre_select='kld', \n",
        "                   tp=True,\n",
        "                   k=30,\n",
        "                   sum=True,\n",
        "                   mu=0.8, # totally not sure about this hyper-parameter\n",
        "                   k1=1.2,\n",
        "                   b=0.75,\n",
        "                   num_docs=20,\n",
        "                   max_span=5):\n",
        "    \"\"\"\n",
        "    Function that retrieves a document ranking for all queries with a\n",
        "    Retrieval Status Value (RSV) based on term-proximity (TP) weighting,\n",
        "    Okapi BM25 or Kullback-Leibler Divergence. When opting for TP, k\n",
        "    documents can be pre-selected with the Okapi BM25 or Kullback-Leibler\n",
        "    Divergence retrieval models. The relevance judgements are also added.\n",
        "\n",
        "    Args:\n",
        "      queries    = [str] filename for search queries CSV\n",
        "      qrels      = [str] filename for relevance judgements CSV\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      tp         = [bool] whether to do the term proximity at all\n",
        "      k          = [int] maximum number of documents to retrieve with\n",
        "                         the pre-selection retrieval model per query\n",
        "      sum        = [bool] whether to sum the pre-selection and term \n",
        "                          proximity scores for the final score\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      num_docs   = [int] maximum number of documents to retrieve per query\n",
        "      max_span   = [int] maximum distance, in number of terms, for a term\n",
        "                         pair to be included in the term proximity score\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output, where the columns are the query id,\n",
        "      the document id, the score of the document given the query, the\n",
        "      rank of the document given the query, and the relevance of the \n",
        "      document given the query.\n",
        "    \"\"\"\n",
        "    # add the queries and qrels tables to the database\n",
        "    db.make_queries(queries, qrels)\n",
        "\n",
        "    # determine the SQL query\n",
        "    sql = (self._qterms(pre_select, tp, True) +\n",
        "           self._qtermstf(pre_select, tp, True) +\n",
        "           self._condocs(db, con_query, tp, True) +\n",
        "           self._pre_select_subscores(db, con_query, pre_select, mu, k1, b, True) +\n",
        "           self._topkdocs(pre_select, k, True) + \n",
        "           self._pairs(con_query, pre_select, tp, max_span, True) +\n",
        "           self._tpscores(db, tp, k1, b, True) +\n",
        "           self._scores(pre_select, tp, sum, num_docs, True) +\n",
        "           self._qrels())    \n",
        "    print('Query: {}'.format(sql))\n",
        "\n",
        "    # get the elapsed time and the results after executing the SQL query\n",
        "    time = datetime.now()\n",
        "    out = db.execute_query(sql)\n",
        "    time_delta = datetime.now() - time\n",
        "    print('Query time: {}'.format(time_delta))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def nr_relevant_documents(self, queries, qrels, db):\n",
        "    \"\"\"Function that retrieves the number of relevant document for each\n",
        "       search query.\n",
        "\n",
        "    Args:\n",
        "      queries = [str] filename for search queries CSV\n",
        "      qrels   = [str] filename for relevance judgements CSV\n",
        "      db      = [DuckDB|MonetDBLite] database that stores the index\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output with the queryid and numreldocs columns.\n",
        "    \"\"\"\n",
        "    # add the queries and qrels tables to the database\n",
        "    db.make_queries(queries, qrels)\n",
        "\n",
        "    # determine the SQL query\n",
        "    sql = (\"SELECT qrels.queryid \" +\n",
        "                 \",COUNT(qrels.name) AS numreldocs \"\n",
        "           \"FROM qrels \"\n",
        "           \"GROUP BY qrels.queryid\")\n",
        "    print('Query: {}'.format(sql))\n",
        "\n",
        "    # get the results after executing the SQL query\n",
        "    out = db.execute_query(sql)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "  def _qterms(self, pre_select, tp, all=False):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, including the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term  \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\"WITH qtermids \"\n",
        "                  \"AS (SELECT dict.termid \"\n",
        "                            \",dict.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM dict \"\n",
        "                      \"{}\"\n",
        "                      \") \"\n",
        "             \"{}\")\n",
        "    \n",
        "    if tp:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"{}\",\n",
        "                           \", qterms \"\n",
        "                                \"AS (SELECT terms.termid \"\n",
        "                                          \",terms.docid \"\n",
        "                                          \",terms.pos \"\n",
        "                                          \",terms.tf \"\n",
        "                                          \",qtermids.df \"\n",
        "                                          \"{}\"\n",
        "                                    \"FROM terms \"\n",
        "                                    \"JOIN qtermids \"\n",
        "                                    \"ON terms.termid = qtermids.termid\"\n",
        "                                    \") \")\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",dict.cf \"\n",
        "                            \"{}\",\n",
        "                            \"{}\",\n",
        "                            \",qtermids.cf \"\n",
        "                            \"{}\")\n",
        "      \n",
        "      if all:\n",
        "        return query.format(\",queries.queryid \"\n",
        "                            \",queries.len \",\n",
        "                            \"JOIN queries \"\n",
        "                            \"ON dict.term = queries.term\",\n",
        "                            \",qtermids.queryid \"\n",
        "                            \",qtermids.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"JOIN query \"\n",
        "                            \"ON dict.term = query.term\",\n",
        "                            \"\")  \n",
        "    else:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",dict.cf \"\n",
        "                            \"{}\",\n",
        "                            \"{}\",\n",
        "                            \"{}\")\n",
        "      \n",
        "      if all:\n",
        "        return query.format(\",queries.queryid \"\n",
        "                            \",queries.len \",\n",
        "                            \"JOIN queries \"\n",
        "                            \"ON dict.term = queries.term\",\n",
        "                            \"\")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"JOIN query \"\n",
        "                            \"ON dict.term = query.term\",\n",
        "                            \"\")\n",
        "\n",
        "  def _qtermstf(self, pre_select, tp, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, excluding the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term\n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "    \n",
        "    query = (\", qtermstfrows \"\n",
        "                  \"AS (SELECT qterms.termid \"\n",
        "                            \",qterms.docid \"\n",
        "                            \",qterms.tf \"\n",
        "                            \"{}\"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                               \"OVER(PARTITION BY {}qterms.termid, qterms.docid \"\n",
        "                                    \"ORDER BY qterms.pos\"\n",
        "                                    \")\"\n",
        "                              \") AS row \"\n",
        "                      \"{}\" \n",
        "                      \") \"\n",
        "             \", qtermstf \"\n",
        "                  \"AS (SELECT qtermstfrows.termid \"\n",
        "                            \",qtermstfrows.docid \"\n",
        "                            \",qtermstfrows.tf \"\n",
        "                            \",qtermstfrows.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM qtermstfrows \"\n",
        "                      \"WHERE qtermstfrows.row = 1\"\n",
        "                      \") \")\n",
        "\n",
        "    if tp:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",qterms.df \"\n",
        "                             \",qterms.cf \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM qterms\",\n",
        "                             \",qtermstfrows.cf \"\n",
        "                             \"{}\")\n",
        "      elif pre_select == 'okapi':\n",
        "        query = query.format(\",qterms.df \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM qterms\",\n",
        "                             \"{}\")\n",
        "        \n",
        "      if all:\n",
        "        return query.format(\",qterms.queryid \"\n",
        "                            \",qterms.len \",\n",
        "                            \"qterms.queryid ,\",\n",
        "                            \",qtermstfrows.queryid \"\n",
        "                            \",qtermstfrows.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\",\n",
        "                            \"\")\n",
        "    else:\n",
        "      if pre_select == 'kld':\n",
        "        query = query.format(\",qtermids.df \"\n",
        "                             \",qtermids.cf \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM terms AS qterms \"\n",
        "                             \"JOIN qtermids \"\n",
        "                             \"ON qterms.termid = qtermids.termid\",\n",
        "                             \",qtermstfrows.cf \"\n",
        "                             \"{}\")  \n",
        "      elif pre_select == 'okapi':\n",
        "        query = query.format(\",qtermids.df \"\n",
        "                             \"{}\",\n",
        "                             \"{}\",\n",
        "                             \"FROM terms AS qterms \"\n",
        "                             \"JOIN qtermids \"\n",
        "                             \"ON qterms.termid = qtermids.termid\",\n",
        "                             \"{}\") \n",
        "         \n",
        "      if all:\n",
        "        return query.format(\",qtermids.queryid \"\n",
        "                            \",qtermids.len \",\n",
        "                            \"qtermids.queryid ,\",\n",
        "                            \",qtermstfrows.queryid \"\n",
        "                            \",qtermstfrows.len \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\",\n",
        "                            \"\")\n",
        "\n",
        "  def _condocs(self, db, con_query, tp, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to documents that contain all the query terms.\n",
        "\n",
        "    Args:\n",
        "      db        = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query = [bool] whether all query terms need to be in\n",
        "                         the document for it to be retrieved\n",
        "      tp        = [bool] whether to do the term proximity\n",
        "      all       = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.                         \n",
        "    \"\"\"\n",
        "    if not con_query:\n",
        "      return \"\"\n",
        "      \n",
        "    query = (\", condocs \"\n",
        "                  \"AS (SELECT qterms.docid \"\n",
        "                      \"{}\"\n",
        "                      \"FROM {} AS qterms \"\n",
        "                      \"GROUP BY qterms.docid \"\n",
        "                      \"{}\"\n",
        "                      \"HAVING COUNT(DISTINCT qterms.termid) = {}\"\n",
        "                      \") \")\n",
        "    if tp:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"qterms\",\n",
        "                           \"{}\",\n",
        "                           \"{}\")\n",
        "    else:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"qtermstf\",\n",
        "                           \"{}\",\n",
        "                           \"{}\")\n",
        "      \n",
        "    if all:\n",
        "      return query.format(\",qterms.queryid \",\n",
        "                          \",qterms.queryid \",\n",
        "                          \"MIN(qterms.len)\")\n",
        "    else:\n",
        "      return query.format(\"\",\n",
        "                          \"\",\n",
        "                          db.len_query)\n",
        "\n",
        "  def _pre_select_subscores(self, db, con_query, pre_select, mu, k1, b, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute a score for each \n",
        "    query term-document pair, according to the pre-selection\n",
        "    retrieval model.\n",
        "\n",
        "    Args:\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved     \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "    \n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "\n",
        "    if pre_select == 'kld':\n",
        "      query = (\", kldsubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \"{}\"\n",
        "                              \",( LOG({:f}+tf*{:f}/cf)\"              \n",
        "                                  \"+\" \n",
        "                                 \"LOG(1/({:f}+docs.len))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(\"{}\", mu, db.C, mu, \"{}\")\n",
        "    elif pre_select == 'okapi':\n",
        "      query = (\", okapisubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \"{}\"\n",
        "                              \",( LOG(({:f}-df+0.5)/(df+0.5))*tf*({:f}+1)\"\n",
        "                                  \"/\"\n",
        "                                 \"(tf+{:f}*(1-{:f}+{:f}*docs.len/{:f}))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(\"{}\", db.N, k1, k1, b, b, db.avgdl, \"{}\")\n",
        "\n",
        "    if con_query:\n",
        "      query = query.format(\"{}\",\n",
        "                           \"JOIN condocs \"\n",
        "                           \"ON qtermstf.docid = condocs.docid \"\n",
        "                           \"{}\")      \n",
        "      if all:\n",
        "        return query.format(\",qtermstf.queryid \",\n",
        "                            \"AND qtermstf.queryid = condocs.queryid \")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\")\n",
        "    else:\n",
        "      if all:\n",
        "        return query.format(\",qtermstf.queryid \",\n",
        "                            \"\")\n",
        "      else:\n",
        "        return query.format(\"\",\n",
        "                            \"\")\n",
        "\n",
        "  def _topkdocs(self, pre_select, k, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the pre-selection scores,\n",
        "    according to the pre-selection retrieval model, and retrieve\n",
        "    the top k documents.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      k          = [int] maximum number of documents retrieved with\n",
        "                         the pre-selection retrieval model\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", topdocs \"\n",
        "                  \"AS (SELECT subscores.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(subscores.subscore) AS score \"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                                \"OVER({}ORDER BY SUM(subscores.subscore) DESC)\"\n",
        "                              \") AS rank \"\n",
        "                      \"FROM {} AS subscores \"\n",
        "                      \"GROUP BY subscores.docid\"\n",
        "                      \"{}\"\n",
        "                      \") \"\n",
        "             \", topkdocs \"\n",
        "                  \"AS (SELECT topdocs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",topdocs.score \"\n",
        "                      \"FROM topdocs \"\n",
        "                      \"WHERE topdocs.rank BETWEEN 1 AND {}\"\n",
        "                      \") \")\n",
        "    \n",
        "    if all:\n",
        "      query = query.format(\",subscores.queryid \",\n",
        "                           \"PARTITION BY subscores.queryid \",\n",
        "                           \"{}\",\n",
        "                           \" ,subscores.queryid\",\n",
        "                           \",topdocs.queryid \",\n",
        "                           \"{:d}\")\n",
        "    else:\n",
        "      query = query.format(\"\",\n",
        "                           \"\",\n",
        "                           \"{}\",\n",
        "                           \"\",\n",
        "                           \"\",\n",
        "                           \"{:d}\")\n",
        "    \n",
        "    if pre_select == 'kld':\n",
        "      return query.format(\"kldsubscores\",\n",
        "                          k)\n",
        "    elif pre_select == 'okapi':\n",
        "      return query.format(\"okapisubscores\",\n",
        "                          k)\n",
        "\n",
        "  def _pairs(self, con_query, pre_select, tp, max_span, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term pair instance (tpi) for\n",
        "    each query term pair within a span of max_span terms.\n",
        "\n",
        "    Args:\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved                          \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model  \n",
        "      tp         = [bool] whether to do the term proximity                   \n",
        "      max_span   = [int] the maximum span, in terms, of a term pair to\n",
        "                        include in the term proximity score\n",
        "      all        = [bool] whether to retrieve a document ranking for\n",
        "                          all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", pairs \"\n",
        "                  \"AS (SELECT qterms1.termid AS termid1 \"\n",
        "                            \",qterms2.termid AS termid2 \"\n",
        "                            \"{}\"\n",
        "                            \",qterms1.docid \"\n",
        "                            \",1.0/(qterms1.pos-qterms2.pos) AS tpi \"\n",
        "                            \",( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df \"\n",
        "                                    \"ELSE qterms2.df \"\n",
        "                               \"END\"\n",
        "                              \") AS maxdf \"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                               \"OVER(PARTITION BY qterms1.termid \"\n",
        "                                                \",qterms2.termid \"\n",
        "                                                \"{}\"\n",
        "                                                \",qterms1.docid \"\n",
        "                                    \"ORDER BY qterms1.pos)\"\n",
        "                              \") AS row \"\n",
        "                      \"FROM qterms AS qterms1 \"\n",
        "                      \"{}\"\n",
        "                      \"{}\"\n",
        "                      \"JOIN qterms AS qterms2 \"\n",
        "                      \"ON qterms1.docid = qterms2.docid AND \"\n",
        "                         \"{}\"\n",
        "                         \"NOT qterms1.termid = qterms2.termid AND \"\n",
        "                         \"qterms1.pos-qterms2.pos BETWEEN 1 AND {:d}\"\n",
        "                      \") \")\n",
        "    \n",
        "    if all:\n",
        "      if con_query:\n",
        "        query = query.format(\",qterms1.queryid \",\n",
        "                             \",qterms1.queryid \",\n",
        "                             \"JOIN condocs ON qterms1.queryid = condocs.queryid \"\n",
        "                             \"AND qterms1.docid = condocs.docid \",\n",
        "                             \"{}\",\n",
        "                             \"qterms1.queryid = qterms2.queryid AND \",\n",
        "                             max_span)\n",
        "      else:\n",
        "        query = query.format(\",qterms1.queryid \",\n",
        "                             \",qterms1.queryid \",\n",
        "                             \"\",\n",
        "                             \"{}\",\n",
        "                             \"qterms1.queryid = qterms2.queryid AND \",\n",
        "                             max_span)\n",
        "        \n",
        "      if pre_select == 'none':\n",
        "        return query.format(\"\")\n",
        "      else:\n",
        "        return query.format(\"JOIN topkdocs ON qterms1.queryid = topkdocs.queryid \"\n",
        "                            \"AND qterms1.docid = topkdocs.docid \")        \n",
        "    else:\n",
        "      if con_query:\n",
        "        query = query.format(\"\",\n",
        "                             \"\",\n",
        "                             \"JOIN condocs ON qterms1.docid = condocs.docid \",\n",
        "                             \"{}\",\n",
        "                             \"\",\n",
        "                             max_span)\n",
        "      else:\n",
        "        query = query.format(\"\",\n",
        "                             \"\",\n",
        "                             \"\",\n",
        "                             \"{}\",\n",
        "                             \"\",\n",
        "                             max_span)\n",
        "        \n",
        "      if pre_select == 'none':\n",
        "        return query.format(\"\")\n",
        "      else:\n",
        "        return query.format(\"JOIN topkdocs ON qterms1.docid = topkdocs.docid \")\n",
        "      \n",
        "  def _tpscores(self, db, tp, k1, b, all=False):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term proximity score.\n",
        "\n",
        "    Args:      \n",
        "      db  = [DuckDB|MonetDBLite] database that stores the index\n",
        "      tp  = [bool] whether to do the term proximity\n",
        "      k1  = [float] hyper-parameter for Okapi BM25\n",
        "      b   = [float] hyper-parameter for Okapi BM25\n",
        "      all = [bool] whether to retrieve a document ranking for all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "      \n",
        "    query = (\", tpisums \"\n",
        "                  \"AS (SELECT pairs.termid1 \"\n",
        "                            \",pairs.termid2 \"\n",
        "                            \",pairs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(pairs.tpi) AS tpisum \"\n",
        "                      \"FROM pairs \"              \n",
        "                      \"GROUP BY pairs.termid1 \"\n",
        "                              \",pairs.termid2 \"\n",
        "                              \",pairs.docid\"\n",
        "                              \"{}\"\n",
        "                      \") \"\n",
        "            \", tpsubscores \"\n",
        "                  \"AS (SELECT pairs.docid \"\n",
        "                            \"{}\"\n",
        "                            \",( LOG(({:f}-maxdf+0.5)/(maxdf+0.5))*tpisum*({:f}+1)\"\n",
        "                                \"/\"\n",
        "                              \"(tpisum+{:f}*(1-{:f}+{:f}*docs.len/{:f}))\"\n",
        "                              \") AS tpsubscore \"\n",
        "                      \"FROM pairs \"\n",
        "                      \"JOIN tpisums \"\n",
        "                      \"ON pairs.termid1 = tpisums.termid1 AND \"\n",
        "                        \"pairs.termid2 = tpisums.termid2 AND \"\n",
        "                        \"pairs.docid = tpisums.docid \"\n",
        "                        \"{}\"\n",
        "                      \"JOIN docs \"\n",
        "                      \"ON pairs.docid = docs.docid \"\n",
        "                      \"WHERE pairs.row = 1\"\n",
        "                      \") \"\n",
        "            \", tpscores \"\n",
        "                  \"AS (SELECT tpsubscores.docid \"\n",
        "                            \"{}\"\n",
        "                            \",SUM(tpsubscores.tpsubscore) AS tpscore \"\n",
        "                      \"FROM tpsubscores \"\n",
        "                      \"GROUP BY tpsubscores.docid\"\n",
        "                      \"{}\"\n",
        "                      \") \")\n",
        "\n",
        "    if all:\n",
        "      return query.format(\",pairs.queryid \",\n",
        "                          \" ,pairs.queryid\",\n",
        "                          \",pairs.queryid \",\n",
        "                          db.N,\n",
        "                          k1,\n",
        "                          k1,\n",
        "                          b,\n",
        "                          b,\n",
        "                          db.avgdl,\n",
        "                          \"AND pairs.queryid = tpisums.queryid \",\n",
        "                          \",tpsubscores.queryid \",\n",
        "                          \" ,tpsubscores.queryid\")\n",
        "    else:\n",
        "      return query.format(\"\",\n",
        "                          \"\",\n",
        "                          \"\",\n",
        "                          db.N,\n",
        "                          k1,\n",
        "                          k1,\n",
        "                          b,\n",
        "                          b,\n",
        "                          db.avgdl,\n",
        "                          \"\",\n",
        "                          \"\",\n",
        "                          \"\")\n",
        "\n",
        "  def _scores(self, pre_select, tp, sum, num_docs, all=False):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve or compute the final document scores.\n",
        "\n",
        "    Args:      \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      sum        = [bool] whether to sum the pre-select and term \n",
        "                          proximity scores for the final score\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "      all        = [bool] whether to retrieve a document ranking\n",
        "                          for all queries\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if all:\n",
        "      query = (\", scores \"\n",
        "                    \"AS ({}) \"\n",
        "                \", topndocs \"\n",
        "                    \"AS (SELECT scores.queryid \"\n",
        "                              \",scores.docid \"\n",
        "                              \",scores.score \"\n",
        "                              \",scores.rank \"\n",
        "                        \"FROM scores \"\n",
        "                        \"WHERE scores.rank BETWEEN 1 and {:d}\"\n",
        "                        \") \")\n",
        "      \n",
        "      if not tp:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.queryid \"\n",
        "                                  \",topkdocs.score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY topkdocs.queryid \"\n",
        "                                          \"ORDER BY topkdocs.score DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs\",\n",
        "                            num_docs)\n",
        "      elif pre_select == 'none' or not sum:\n",
        "        return query.format(\"SELECT tpscores.docid \"\n",
        "                                  \",tpscores.queryid \"\n",
        "                                  \",tpscores.tpscore AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY tpscores.queryid \"\n",
        "                                          \"ORDER BY tpscores.tpscore DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM tpscores\",\n",
        "                            num_docs)\n",
        "      else:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.queryid \"\n",
        "                                  \",( topkdocs.score\"\n",
        "                                      \"+\"\n",
        "                                    \"COALESCE(tpscores.tpscore, 0)\"\n",
        "                                    \") AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(PARTITION BY topkdocs.queryid \"\n",
        "                                          \"ORDER BY topkdocs.score\"\n",
        "                                                    \"+\"\n",
        "                                                   \"COALESCE(tpscores.tpscore, 0) \"\n",
        "                                                \"DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs \"\n",
        "                            \"LEFT JOIN tpscores \"\n",
        "                            \"ON topkdocs.docid = tpscores.docid AND \"\n",
        "                               \"topkdocs.queryid = tpscores.queryid\",\n",
        "                            num_docs)\n",
        "    else:           \n",
        "      query = (\", scores \"\n",
        "                    \"AS ({}) \"\n",
        "                \"SELECT scores.docid \"\n",
        "                      \",scores.score \"\n",
        "                      \",scores.rank \"\n",
        "                \"FROM scores \"\n",
        "                \"WHERE scores.rank BETWEEN 1 AND {:d}\")\n",
        "      \n",
        "      if not tp:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",topkdocs.score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY topkdocs.score DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs\",\n",
        "                            num_docs)\n",
        "      elif pre_select == 'none' or not sum:\n",
        "        return query.format(\"SELECT tpscores.docid \"\n",
        "                                  \",tpscores.tpscore AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY tpscores.tpscore DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM tpscores\",\n",
        "                            num_docs)\n",
        "      else:\n",
        "        return query.format(\"SELECT topkdocs.docid \"\n",
        "                                  \",( topkdocs.score\"\n",
        "                                      \"+\"\n",
        "                                    \"COALESCE(tpscores.tpscore, 0)\"\n",
        "                                    \") AS score \"\n",
        "                                  \",( ROW_NUMBER() \"\n",
        "                                     \"OVER(ORDER BY topkdocs.score\"\n",
        "                                                    \"+\"\n",
        "                                                   \"COALESCE(tpscores.tpscore, 0) \"\n",
        "                                          \"DESC)\"\n",
        "                                    \") AS rank \"\n",
        "                            \"FROM topkdocs \"\n",
        "                            \"LEFT JOIN tpscores \"\n",
        "                            \"ON topkdocs.docid = tpscores.docid\",\n",
        "                            num_docs)\n",
        "        \n",
        "  def _qrels(self):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve the relevance judgement for each\n",
        "    retrieved query-document pair.\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\"SELECT topndocs.queryid \"\n",
        "                   \",docs.name \"\n",
        "                   \",topndocs.score \"\n",
        "                   \",topndocs.rank \"\n",
        "                   \",COALESCE(qrels.rel, 0) AS rel \"\n",
        "             \"FROM topndocs \"\n",
        "             \"JOIN docs \"\n",
        "             \"ON topndocs.docid = docs.docid \"\n",
        "             \"LEFT JOIN qrels \"\n",
        "             \"ON topndocs.queryid = qrels.queryid AND \"\n",
        "                \"docs.name = qrels.name\")\n",
        "    return query"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPKySlkvO4-0",
        "colab_type": "text"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Both databases are initialized, which loads the indices in the databases and makes them ready for execution. This can take about 5 minutes, so time for coffee!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0DVuHD8yaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck = DuckDB()\n",
        "monet = MonetDBLite()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXXbESd9PoiE",
        "colab_type": "text"
      },
      "source": [
        "The `Retriever` class does not have a constructor, so initializing it is a bit meaningless. I still prefer to put it in a class to hide the private methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvqmT_067S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retriever = Retriever()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfDXKjOhXLU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "9d6f5560-6334-4dd5-95fe-6476ed64f4f9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/nnistelrooij/Information-Retrieval/master/data/test_queries.csv"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-09 15:52:59--  https://raw.githubusercontent.com/nnistelrooij/Information-Retrieval/master/data/test_queries.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9292 (9.1K) [text/plain]\n",
            "Saving to: ‘test_queries.csv’\n",
            "\n",
            "\rtest_queries.csv      0%[                    ]       0  --.-KB/s               \rtest_queries.csv    100%[===================>]   9.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-09 15:52:59 (185 MB/s) - ‘test_queries.csv’ saved [9292/9292]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUM6SuVjZ1kM",
        "colab_type": "text"
      },
      "source": [
        "## Retrieving the number of relevant document for each search query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcqehyCkM4I4",
        "colab_type": "code",
        "outputId": "d0e7ccb6-ce96-48cb-ba16-5b2703678fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "duck_num_rel_docs = retriever.nr_relevant_documents('test_queries.csv', 'qrels.csv', duck)\n",
        "monet_num_rel_docs = retriever.nr_relevant_documents('test_queries.csv', 'qrels.csv', monet)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: SELECT qrels.queryid ,COUNT(qrels.name) AS numreldocs FROM qrels GROUP BY qrels.queryid\n",
            "Query: SELECT qrels.queryid ,COUNT(qrels.name) AS numreldocs FROM qrels GROUP BY qrels.queryid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqfCiVFWXedi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0d108fe1-f3d7-46de-a3b4-e31c8e8e30b3"
      },
      "source": [
        "duck_num_rel_docs"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>numreldocs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>609</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>308</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>445</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>686</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>604</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>693</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>428</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>421</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>664</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>353</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     queryid  numreldocs\n",
              "0        609          30\n",
              "1        308           4\n",
              "2        445          62\n",
              "3        686          32\n",
              "4        604           8\n",
              "..       ...         ...\n",
              "244      693          27\n",
              "245      428         118\n",
              "246      421          83\n",
              "247      664           9\n",
              "248      353         122\n",
              "\n",
              "[249 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKT3utMnXf1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "fb021772-349e-4496-f1ed-f5d6d135a466"
      },
      "source": [
        "monet_num_rel_docs"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>numreldocs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>301</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>302</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>303</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>304</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>305</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>696</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>697</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>698</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>699</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>700</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     queryid  numreldocs\n",
              "0        301         448\n",
              "1        302          65\n",
              "2        303          10\n",
              "3        304         196\n",
              "4        305          35\n",
              "..       ...         ...\n",
              "244      696          31\n",
              "245      697          50\n",
              "246      698          10\n",
              "247      699          71\n",
              "248      700         120\n",
              "\n",
              "[249 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hin6IHmrc1x",
        "colab_type": "text"
      },
      "source": [
        "## Retrieving documents for all Robust04 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltD5O2EfJJiZ",
        "colab_type": "code",
        "outputId": "d03dfb1b-d436-4fdf-a412-a8c535d3bfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "duck_rels = retriever.retrieve_all('queries_test.csv', 'qrels.csv', duck)\n",
        "monet_rels = retriever.retrieve_all('queries_test.csv', 'qrels.csv', monet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf ,queries.queryid ,queries.len FROM dict JOIN queries ON dict.term = queries.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df ,qtermids.cf ,qtermids.queryid ,qtermids.len FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,qterms.cf ,qterms.queryid ,qterms.len ,( ROW_NUMBER() OVER(PARTITION BY qterms.queryid ,qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf ,qtermstfrows.queryid ,qtermstfrows.len FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid ,qterms.queryid FROM qterms AS qterms GROUP BY qterms.docid ,qterms.queryid HAVING COUNT(DISTINCT qterms.termid) = MIN(qterms.len)) , kldsubscores AS (SELECT qtermstf.docid ,qtermstf.queryid ,( LOG(0.800000+tf*174540872.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid AND qtermstf.queryid = condocs.queryid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,subscores.queryid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(PARTITION BY subscores.queryid ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid ,subscores.queryid) , topkdocs AS (SELECT topdocs.docid ,topdocs.queryid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.queryid ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.queryid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.queryid = condocs.queryid AND qterms1.docid = condocs.docid JOIN topkdocs ON qterms1.queryid = topkdocs.queryid AND qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND qterms1.queryid = qterms2.queryid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid) , tpsubscores AS (SELECT pairs.docid ,pairs.queryid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid AND pairs.queryid = tpisums.queryid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,tpsubscores.queryid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid ,tpsubscores.queryid) , scores AS (SELECT topkdocs.docid ,topkdocs.queryid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(PARTITION BY topkdocs.queryid ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid AND topkdocs.queryid = tpscores.queryid) , topndocs AS (SELECT scores.queryid ,scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 and 20) SELECT topndocs.queryid ,docs.name ,topndocs.score ,topndocs.rank ,COALESCE(qrels.rel, 0) AS rel FROM topndocs JOIN docs ON topndocs.docid = docs.docid LEFT JOIN qrels ON topndocs.queryid = qrels.queryid AND docs.name = qrels.name\n",
            "Query time: 0:00:26.317280\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf ,queries.queryid ,queries.len FROM dict JOIN queries ON dict.term = queries.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df ,qtermids.cf ,qtermids.queryid ,qtermids.len FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,qterms.cf ,qterms.queryid ,qterms.len ,( ROW_NUMBER() OVER(PARTITION BY qterms.queryid ,qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf ,qtermstfrows.queryid ,qtermstfrows.len FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid ,qterms.queryid FROM qterms AS qterms GROUP BY qterms.docid ,qterms.queryid HAVING COUNT(DISTINCT qterms.termid) = MIN(qterms.len)) , kldsubscores AS (SELECT qtermstf.docid ,qtermstf.queryid ,( LOG(0.800000+tf*174540872.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid AND qtermstf.queryid = condocs.queryid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,subscores.queryid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(PARTITION BY subscores.queryid ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid ,subscores.queryid) , topkdocs AS (SELECT topdocs.docid ,topdocs.queryid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.queryid ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.queryid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.queryid = condocs.queryid AND qterms1.docid = condocs.docid JOIN topkdocs ON qterms1.queryid = topkdocs.queryid AND qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND qterms1.queryid = qterms2.queryid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid ,pairs.queryid) , tpsubscores AS (SELECT pairs.docid ,pairs.queryid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid AND pairs.queryid = tpisums.queryid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,tpsubscores.queryid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid ,tpsubscores.queryid) , scores AS (SELECT topkdocs.docid ,topkdocs.queryid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(PARTITION BY topkdocs.queryid ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid AND topkdocs.queryid = tpscores.queryid) , topndocs AS (SELECT scores.queryid ,scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 and 20) SELECT topndocs.queryid ,docs.name ,topndocs.score ,topndocs.rank ,COALESCE(qrels.rel, 0) AS rel FROM topndocs JOIN docs ON topndocs.docid = docs.docid LEFT JOIN qrels ON topndocs.queryid = qrels.queryid AND docs.name = qrels.name\n",
            "Query time: 0:00:00.492812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mpB_RwLjrxY",
        "colab_type": "code",
        "outputId": "facd525d-6762-4d73-e457-f1024e8f85c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "duck_rels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "      <th>rel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-67889</td>\n",
              "      <td>4.901532</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>319</td>\n",
              "      <td>LA071889-0090</td>\n",
              "      <td>4.701030</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>319</td>\n",
              "      <td>LA032790-0025</td>\n",
              "      <td>4.599285</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>319</td>\n",
              "      <td>LA082490-0168</td>\n",
              "      <td>4.059729</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940317-2-00038</td>\n",
              "      <td>3.996822</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-64392</td>\n",
              "      <td>3.931923</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-27184</td>\n",
              "      <td>3.915063</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>319</td>\n",
              "      <td>LA082990-0110</td>\n",
              "      <td>3.903385</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940208-1-00043</td>\n",
              "      <td>3.886484</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940407-0-00070</td>\n",
              "      <td>3.878751</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-59651</td>\n",
              "      <td>3.777882</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>320</td>\n",
              "      <td>FR941104-2-00033</td>\n",
              "      <td>15.679460</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-59596</td>\n",
              "      <td>12.041131</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-24644</td>\n",
              "      <td>10.425788</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>320</td>\n",
              "      <td>LA071789-0059</td>\n",
              "      <td>6.653320</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-43166</td>\n",
              "      <td>5.126421</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-43220</td>\n",
              "      <td>5.126421</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>319</td>\n",
              "      <td>LA081590-0148</td>\n",
              "      <td>4.391461</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-28321</td>\n",
              "      <td>4.110349</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-42072</td>\n",
              "      <td>4.110349</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-66452</td>\n",
              "      <td>4.047556</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>319</td>\n",
              "      <td>LA011490-0086</td>\n",
              "      <td>3.955540</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-11346</td>\n",
              "      <td>3.924537</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940228-2-00043</td>\n",
              "      <td>3.730987</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>320</td>\n",
              "      <td>LA031590-0184</td>\n",
              "      <td>14.452581</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-47355</td>\n",
              "      <td>4.396453</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>319</td>\n",
              "      <td>LA020390-0024</td>\n",
              "      <td>4.011823</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    queryid              name      score  rank  rel\n",
              "0       319       FBIS4-67889   4.901532     1    0\n",
              "1       319     LA071889-0090   4.701030     2    0\n",
              "2       319     LA032790-0025   4.599285     3    0\n",
              "3       319     LA082490-0168   4.059729     8    0\n",
              "4       319  FR940317-2-00038   3.996822    11    0\n",
              "5       319       FBIS4-64392   3.931923    13    0\n",
              "6       319       FBIS4-27184   3.915063    15    0\n",
              "7       319     LA082990-0110   3.903385    16    0\n",
              "8       319  FR940208-1-00043   3.886484    17    0\n",
              "9       319  FR940407-0-00070   3.878751    18    0\n",
              "10      319       FBIS3-59651   3.777882    19    0\n",
              "11      320  FR941104-2-00033  15.679460     1    0\n",
              "12      320       FBIS3-59596  12.041131     3    0\n",
              "13      320       FBIS3-24644  10.425788     4    0\n",
              "14      320     LA071789-0059   6.653320     5    0\n",
              "15      320       FBIS3-43166   5.126421     6    0\n",
              "16      320       FBIS3-43220   5.126421     7    0\n",
              "17      319     LA081590-0148   4.391461     5    0\n",
              "18      319       FBIS3-28321   4.110349     6    0\n",
              "19      319       FBIS3-42072   4.110349     7    0\n",
              "20      319       FBIS4-66452   4.047556     9    0\n",
              "21      319     LA011490-0086   3.955540    12    0\n",
              "22      319       FBIS4-11346   3.924537    14    0\n",
              "23      319  FR940228-2-00043   3.730987    20    0\n",
              "24      320     LA031590-0184  14.452581     2    0\n",
              "25      319       FBIS4-47355   4.396453     4    0\n",
              "26      319     LA020390-0024   4.011823    10    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ93Q97jsea",
        "colab_type": "code",
        "outputId": "d0f63947-7268-485e-f3aa-299462884b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "monet_rels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "      <th>rel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-28321</td>\n",
              "      <td>11.990903</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS3-42072</td>\n",
              "      <td>11.990903</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-66452</td>\n",
              "      <td>10.718246</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-67889</td>\n",
              "      <td>12.392103</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>320</td>\n",
              "      <td>FR941104-2-00033</td>\n",
              "      <td>46.767411</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>320</td>\n",
              "      <td>LA031590-0184</td>\n",
              "      <td>45.125368</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-59596</td>\n",
              "      <td>34.671905</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-24644</td>\n",
              "      <td>30.084404</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>320</td>\n",
              "      <td>LA071789-0059</td>\n",
              "      <td>17.531671</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-43220</td>\n",
              "      <td>13.246727</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>320</td>\n",
              "      <td>FBIS3-43166</td>\n",
              "      <td>13.246727</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>319</td>\n",
              "      <td>LA032790-0025</td>\n",
              "      <td>12.698805</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>319</td>\n",
              "      <td>LA020390-0024</td>\n",
              "      <td>11.686000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>319</td>\n",
              "      <td>LA071889-0090</td>\n",
              "      <td>10.824522</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-47355</td>\n",
              "      <td>10.817496</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>319</td>\n",
              "      <td>LA081590-0148</td>\n",
              "      <td>10.111713</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940407-0-00070</td>\n",
              "      <td>9.766341</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940208-1-00043</td>\n",
              "      <td>9.500112</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>319</td>\n",
              "      <td>LA082990-0110</td>\n",
              "      <td>9.460871</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940228-2-00043</td>\n",
              "      <td>9.455121</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940304-2-00030</td>\n",
              "      <td>9.455121</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940425-2-00042</td>\n",
              "      <td>9.391686</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>319</td>\n",
              "      <td>FR941007-2-00055</td>\n",
              "      <td>9.366639</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>319</td>\n",
              "      <td>FR940317-2-00038</td>\n",
              "      <td>9.363224</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-64392</td>\n",
              "      <td>9.356824</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>319</td>\n",
              "      <td>LA082490-0168</td>\n",
              "      <td>9.347871</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>319</td>\n",
              "      <td>FBIS4-11346</td>\n",
              "      <td>9.310473</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    queryid              name      score  rank  rel\n",
              "0       319       FBIS3-28321  11.990903     3    1\n",
              "1       319       FBIS3-42072  11.990903     4    1\n",
              "2       319       FBIS4-66452  10.718246     8    1\n",
              "3       319       FBIS4-67889  12.392103     2    1\n",
              "4       320  FR941104-2-00033  46.767411     1    0\n",
              "5       320     LA031590-0184  45.125368     2    0\n",
              "6       320       FBIS3-59596  34.671905     3    0\n",
              "7       320       FBIS3-24644  30.084404     4    0\n",
              "8       320     LA071789-0059  17.531671     5    0\n",
              "9       320       FBIS3-43220  13.246727     6    0\n",
              "10      320       FBIS3-43166  13.246727     7    0\n",
              "11      319     LA032790-0025  12.698805     1    0\n",
              "12      319     LA020390-0024  11.686000     5    0\n",
              "13      319     LA071889-0090  10.824522     6    0\n",
              "14      319       FBIS4-47355  10.817496     7    0\n",
              "15      319     LA081590-0148  10.111713     9    0\n",
              "16      319  FR940407-0-00070   9.766341    10    0\n",
              "17      319  FR940208-1-00043   9.500112    11    0\n",
              "18      319     LA082990-0110   9.460871    12    0\n",
              "19      319  FR940228-2-00043   9.455121    13    0\n",
              "20      319  FR940304-2-00030   9.455121    14    0\n",
              "21      319  FR940425-2-00042   9.391686    15    0\n",
              "22      319  FR941007-2-00055   9.366639    16    0\n",
              "23      319  FR940317-2-00038   9.363224    17    0\n",
              "24      319       FBIS4-64392   9.356824    18    0\n",
              "25      319     LA082490-0168   9.347871    19    0\n",
              "26      319       FBIS4-11346   9.310473    20    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uvmhehsUxY2",
        "colab_type": "text"
      },
      "source": [
        "## Options\n",
        "\n",
        "Now we will explain how to use this complicated `retrieve()` function by setting a number of specific options on or off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRFX-M6HQPlM",
        "colab_type": "text"
      },
      "source": [
        "### All options\n",
        "\n",
        "Let's start with the default options. The query will be (`query=`)*new york* and it will be executed for both databases (`db=DuckDB` and `db=MonetDBLite`).\n",
        "\n",
        "First, the top (`k=`)30 documents are retrieved using the Kullback-Leibler Divergence (`pre_select='kld'`) retrieval model with conjunctive queries (`con_query=True`) and a $\\mu$ of 0.8 (`mu=0.8`). Then, these 30 documents are scored again with term proximity weighting (`tp=True`) based on a modified version of the [Rasolofo algorithm](https://www.researchgate.net/publication/225174089_Term_Proximity_Scoring_for_Keyword-Based_Retrieval_Systems), with a $k1$ of 1.2 (`k1=1.2`), a $b$ of 0.75 (`b=0.75`), and a maximum distance of 5 (`max_span=5`) between query terms. The scores obtained from KLD and Rasolofo are summed (`sum=True`) to arrive at the final score and ranking. Of this final ranking, 20 documents are retrieved (`num_docs=20`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgVPDEmB4Igm",
        "colab_type": "code",
        "outputId": "23535bb8-d38d-4bc2-f0d3-d613b30c610d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "query = ['undersea', 'fiber', 'optic', 'cable']\n",
        "\n",
        "print(\"DuckDB with all options\")\n",
        "duck_scores = retriever.retrieve(query, duck)\n",
        "\n",
        "print(\"\\nMonetDBLite with all options\")\n",
        "monet_scores = retriever.retrieve(query, monet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DuckDB with all options\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df ,dict.cf FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df ,qtermids.cf FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,qterms.cf ,( ROW_NUMBER() OVER(PARTITION BY qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df ,qtermstfrows.cf FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 4) , kldsubscores AS (SELECT qtermstf.docid ,( LOG(0.800000+tf*174540872.000000/cf)+LOG(1/(0.800000+docs.len))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM kldsubscores AS subscores GROUP BY subscores.docid) , topkdocs AS (SELECT topdocs.docid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN topkdocs ON qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT topkdocs.docid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:16.459772\n",
            "\n",
            "MonetDBLite with all options\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_gH2BcUrG1",
        "colab_type": "text"
      },
      "source": [
        "DuckDB was very slow compared to MonetDBLite (approximately a factor of 35). The query that both databases execute is identical, so the time difference is purely DuckDB's shortcoming. Furthermore, the actual scores from DuckDB are different than from MonetDBLite. However, the ranking, surprisingly, is identical between the two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nDcip3n5UyA",
        "colab_type": "code",
        "outputId": "04ece1c8-7d65-4be4-edcd-8c7d0f611ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>479480</td>\n",
              "      <td>20.310829</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324380</td>\n",
              "      <td>19.597698</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>353304</td>\n",
              "      <td>15.057817</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>343833</td>\n",
              "      <td>13.065491</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>296092</td>\n",
              "      <td>7.613908</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>442626</td>\n",
              "      <td>5.752981</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>395126</td>\n",
              "      <td>5.752981</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid      score  rank\n",
              "0  479480  20.310829     1\n",
              "1  324380  19.597698     2\n",
              "2  353304  15.057817     3\n",
              "3  343833  13.065491     4\n",
              "4  296092   7.613908     5\n",
              "5  442626   5.752981     6\n",
              "6  395126   5.752981     7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gn2sGid5XyU",
        "colab_type": "code",
        "outputId": "8824c44d-fb89-4aed-f71d-8c96b25148da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>479480</td>\n",
              "      <td>46.767411</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324380</td>\n",
              "      <td>45.125368</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>353304</td>\n",
              "      <td>34.671905</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>343833</td>\n",
              "      <td>30.084404</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>296092</td>\n",
              "      <td>17.531671</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>395126</td>\n",
              "      <td>13.246727</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>442626</td>\n",
              "      <td>13.246727</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid      score  rank\n",
              "0  479480  46.767411     1\n",
              "1  324380  45.125368     2\n",
              "2  353304  34.671905     3\n",
              "3  343833  30.084404     4\n",
              "4  296092  17.531671     5\n",
              "5  395126  13.246727     6\n",
              "6  442626  13.246727     7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlRmarebV0X8",
        "colab_type": "text"
      },
      "source": [
        "### No term proximity weighting\n",
        "\n",
        "If you only want to rank the documents based on Okapi BM25, then run the following code. All the other options, where applicable, are still the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK93im7CVw45",
        "colab_type": "code",
        "outputId": "9fbb7b7f-29fc-4ce3-e39c-39dffebda2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "query = ['undersea', 'fiber', 'optic', 'cable']\n",
        "\n",
        "# print(\"DuckDB with only Okapi BM25\")\n",
        "# duck_scores = retriever.retrieve(query, duck, pre_select='okapi')\n",
        "\n",
        "print(\"\\nMonetDBLite with  only Okapi BM25\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='okapi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MonetDBLite with  only Okapi BM25\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , qtermstfrows AS (SELECT qterms.termid ,qterms.docid ,qterms.tf ,qterms.df ,( ROW_NUMBER() OVER(PARTITION BY qterms.termid, qterms.docid ORDER BY qterms.pos)) AS row FROM qterms) , qtermstf AS (SELECT qtermstfrows.termid ,qtermstfrows.docid ,qtermstfrows.tf ,qtermstfrows.df FROM qtermstfrows WHERE qtermstfrows.row = 1) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 4) , okapisubscores AS (SELECT qtermstf.docid ,( LOG((528030.000000-df+0.5)/(df+0.5))*tf*(1.200000+1)/(tf+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS subscore FROM qtermstf JOIN condocs ON qtermstf.docid = condocs.docid JOIN docs ON qtermstf.docid = docs.docid) , topdocs AS (SELECT subscores.docid ,SUM(subscores.subscore) AS score ,( ROW_NUMBER() OVER(ORDER BY SUM(subscores.subscore) DESC)) AS rank FROM okapisubscores AS subscores GROUP BY subscores.docid) , topkdocs AS (SELECT topdocs.docid ,topdocs.score FROM topdocs WHERE topdocs.rank BETWEEN 1 AND 30) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN topkdocs ON qterms1.docid = topkdocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT topkdocs.docid ,( topkdocs.score+COALESCE(tpscores.tpscore, 0)) AS score ,( ROW_NUMBER() OVER(ORDER BY topkdocs.score+COALESCE(tpscores.tpscore, 0) DESC)) AS rank FROM topkdocs LEFT JOIN tpscores ON topkdocs.docid = tpscores.docid) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:00.241481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6XrXrmW4lJ",
        "colab_type": "text"
      },
      "source": [
        "The difference in time between DuckDB and MonetDBLite is now much smaller (a factor of about 10), but the scores are still different, whereas the ranking is again identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TV9ClY3Wk37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRqb0iFWlx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VLDFS-AXI1w",
        "colab_type": "text"
      },
      "source": [
        "### Only term proximity weighting\n",
        "\n",
        "If you do not want to pre-select `k` documents, before computing the Rasolofo score, then run the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzTTWCIXbOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with only Rasolofo\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none')\n",
        "\n",
        "print(\"\\nMonetDBLite with only Rasolofo\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzHjlAFSX327",
        "colab_type": "text"
      },
      "source": [
        "The factor in the time difference is approximately 10. The execution time for MonetDBLite is more than previously. This makes sense; the algorithm needs to find the close query term pairs in all the documents instead of only the top 30 documents. This operation has a super-linear running time, so it takes MonetDBLite longer to produce the output.\n",
        "\n",
        "The scores are again different, but now the ranking is also different. So DuckDB does not work for the given query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N3a41GsXl-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWj_nAS3Xn3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezy8UUQ1YrhR",
        "colab_type": "text"
      },
      "source": [
        "### Bigger term pair radius\n",
        "\n",
        "If the Rasolofo algorithm retrieves too few documents with the default parameters, the span of a term pair can be expanded to include more documents. To do that, run the below code with the query *wizard hat*.\n",
        "\n",
        "It is slightly slower than the default span with MonetDBLite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RdGwDm3Y7tM",
        "colab_type": "code",
        "outputId": "13697fb9-27f2-4e6f-e3eb-0004f32df495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "query = ['wizard', 'hat']\n",
        "\n",
        "print(\"DuckDB with default term pair span\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none')\n",
        "\n",
        "print(\"\\nMonetDBLite with default term pair span\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DuckDB with default term pair span\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT tpscores.docid ,tpscores.tpscore AS score ,( ROW_NUMBER() OVER(ORDER BY tpscores.tpscore DESC)) AS rank FROM tpscores) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:06.643055\n",
            "\n",
            "MonetDBLite with default term pair span\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 5) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT tpscores.docid ,tpscores.tpscore AS score ,( ROW_NUMBER() OVER(ORDER BY tpscores.tpscore DESC)) AS rank FROM tpscores) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:00.272600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEYnzs4naAgP",
        "colab_type": "code",
        "outputId": "5390fd5f-233c-4a90-c013-ce83de50bd99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181649</td>\n",
              "      <td>0.545715</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid     score  rank\n",
              "0  181649  0.545715     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ehWfvUzaBca",
        "colab_type": "code",
        "outputId": "694dd1c7-005c-4d98-f1e0-4a04a4350942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181649</td>\n",
              "      <td>1.256556</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid     score  rank\n",
              "0  181649  1.256556     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQhJyibdZI9e",
        "colab_type": "code",
        "outputId": "0c7a3537-e848-4a69-c695-5017504dc4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "print(\"DuckDB with bigger term pair span\")\n",
        "duck_scores = retriever.retrieve(query, duck, pre_select='none', max_span=20)\n",
        "\n",
        "print(\"\\nMonetDBLite with bigger term pair span\")\n",
        "monet_scores = retriever.retrieve(query, monet, pre_select='none', max_span=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DuckDB with bigger term pair span\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 20) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT tpscores.docid ,tpscores.tpscore AS score ,( ROW_NUMBER() OVER(ORDER BY tpscores.tpscore DESC)) AS rank FROM tpscores) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:06.691399\n",
            "\n",
            "MonetDBLite with bigger term pair span\n",
            "Query: WITH qtermids AS (SELECT dict.termid ,dict.df FROM dict JOIN query ON dict.term = query.term) , qterms AS (SELECT terms.termid ,terms.docid ,terms.pos ,terms.tf ,qtermids.df FROM terms JOIN qtermids ON terms.termid = qtermids.termid) , condocs AS (SELECT qterms.docid FROM qterms AS qterms GROUP BY qterms.docid HAVING COUNT(DISTINCT qterms.termid) = 2) , pairs AS (SELECT qterms1.termid AS termid1 ,qterms2.termid AS termid2 ,qterms1.docid ,1.0/(qterms1.pos-qterms2.pos) AS tpi ,( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df ELSE qterms2.df END) AS maxdf ,( ROW_NUMBER() OVER(PARTITION BY qterms1.termid ,qterms2.termid ,qterms1.docid ORDER BY qterms1.pos)) AS row FROM qterms AS qterms1 JOIN condocs ON qterms1.docid = condocs.docid JOIN qterms AS qterms2 ON qterms1.docid = qterms2.docid AND NOT qterms1.termid = qterms2.termid AND qterms1.pos-qterms2.pos BETWEEN 1 AND 20) , tpisums AS (SELECT pairs.termid1 ,pairs.termid2 ,pairs.docid ,SUM(pairs.tpi) AS tpisum FROM pairs GROUP BY pairs.termid1 ,pairs.termid2 ,pairs.docid) , tpsubscores AS (SELECT pairs.docid ,( LOG((528030.000000-maxdf+0.5)/(maxdf+0.5))*tpisum*(1.200000+1)/(tpisum+1.200000*(1-0.750000+0.750000*docs.len/330.551052))) AS tpsubscore FROM pairs JOIN tpisums ON pairs.termid1 = tpisums.termid1 AND pairs.termid2 = tpisums.termid2 AND pairs.docid = tpisums.docid JOIN docs ON pairs.docid = docs.docid WHERE pairs.row = 1) , tpscores AS (SELECT tpsubscores.docid ,SUM(tpsubscores.tpsubscore) AS tpscore FROM tpsubscores GROUP BY tpsubscores.docid) , scores AS (SELECT tpscores.docid ,tpscores.tpscore AS score ,( ROW_NUMBER() OVER(ORDER BY tpscores.tpscore DESC)) AS rank FROM tpscores) SELECT scores.docid ,scores.score ,scores.rank FROM scores WHERE scores.rank BETWEEN 1 AND 20\n",
            "Query time: 0:00:00.226564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MA5wns7aO2b",
        "colab_type": "code",
        "outputId": "0613e068-c82a-4d65-ba84-788de80800f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181649</td>\n",
              "      <td>0.545715</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>229075</td>\n",
              "      <td>0.270990</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>266854</td>\n",
              "      <td>0.164480</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322002</td>\n",
              "      <td>0.122043</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>293529</td>\n",
              "      <td>0.082593</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid     score  rank\n",
              "0  181649  0.545715     1\n",
              "1  229075  0.270990     2\n",
              "2  266854  0.164480     3\n",
              "3  322002  0.122043     4\n",
              "4  293529  0.082593     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shbxRlsWaPjw",
        "colab_type": "code",
        "outputId": "58b306f9-3014-4f51-bdab-8ae5bbbfaf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181649</td>\n",
              "      <td>1.256556</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>229075</td>\n",
              "      <td>0.623979</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>266854</td>\n",
              "      <td>0.378729</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322002</td>\n",
              "      <td>0.281014</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>293529</td>\n",
              "      <td>0.190178</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    docid     score  rank\n",
              "0  181649  1.256556     1\n",
              "1  229075  0.623979     2\n",
              "2  266854  0.378729     3\n",
              "3  322002  0.281014     4\n",
              "4  293529  0.190178     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LaK3trkapWz",
        "colab_type": "text"
      },
      "source": [
        "### Only TP scores\n",
        "\n",
        "If you want that the final score is only the Rasolofo score, then set `sum=False`. So not the sum of the pre-selection score and the Rasolofo score as final score, but only the Rasolofo score. If the Rasolofo algorithm could not score a document that was retrieved by the pre-selection retrieval model, then that document will not be included in the ranking. So do be aware of that when setting this option!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P31m40X0bmgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with summed scores\")\n",
        "duck_scores = retriever.retrieve(query, duck)\n",
        "\n",
        "print(\"\\nMonetDBLite with summed scores\")\n",
        "monet_scores = retriever.retrieve(query, monet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDIoEXrfb52u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2zsci_Xb6sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCNajxI1b9op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"DuckDB with Rasolofo scores\")\n",
        "duck_scores = retriever.retrieve(query, duck, sum=False)\n",
        "\n",
        "print(\"\\nMonetDBLite with Rasolofo scores\")\n",
        "monet_scores = retriever.retrieve(query, monet, sum=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ZkxekJcC9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnL9g2NscENC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxId-FH-cQ43",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "As seen by the many options, there are endless opportunities for research and evaluation. And we haven't even talked about combining options, disjunctive queries, or hyper-parameters, yet.\n",
        "\n",
        "Our question right now is basically: why is DuckDB so slow and why does DuckDB give incorrect and unintuitive results. Analyzing the runtime of MonetDBLite was much more straightforward than for DuckDB. Is there still some hope for DuckDB, maybe in the future? Or should we only focus on MonetDBLite and maybe implement a second term proximity retrieval model, instead of comparing the two databases?"
      ]
    }
  ]
}