{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OneFunction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkE-y3cGS1MO",
        "colab_type": "code",
        "outputId": "9dea200b-48ce-4af5-dec7-d1729ec1de5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "!wget -O Robust04.rar https://dl.dropboxusercontent.com/s/5qwq3gn6rto98sd/Robust04%2Bpos%2Btf%2Bcf.rar?dl=0\n",
        "!unrar e -o+ Robust04.rar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-19 13:29:12--  https://dl.dropboxusercontent.com/s/5qwq3gn6rto98sd/Robust04%2Bpos%2Btf%2Bcf.rar?dl=0\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460221412 (439M) [application/rar]\n",
            "Saving to: ‘Robust04.rar’\n",
            "\n",
            "Robust04.rar        100%[===================>] 438.90M  46.8MB/s    in 16s     \n",
            "\n",
            "2019-11-19 13:29:29 (26.8 MB/s) - ‘Robust04.rar’ saved [460221412/460221412]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Robust04.rar\n",
            "\n",
            "Extracting  terms.csv                                                    \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  dict.csv                                                     \b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  docs.csv                                                     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XbFCaWPzLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOnPbiYTEph",
        "colab_type": "code",
        "outputId": "3276988e-5b22-42e9-e3a1-acabc10bd2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!pip install duckdb\n",
        "import duckdb\n",
        "\n",
        "class DuckDB(object):\n",
        "  \"\"\"\n",
        "  Class that houses all the DuckDB functionalities.\n",
        "\n",
        "  Attributes:\n",
        "    c         = [Cursor] database cursor of DuckDB\n",
        "    C         = [int] number of indexed terms\n",
        "    N         = [int] number of indexed documents\n",
        "    avgdl     = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database=':memory:',\n",
        "               dict='dict.csv',\n",
        "               docs='docs.csv',\n",
        "               terms='terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes DuckDB database with index and statistics.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    con = duckdb.connect(database)\n",
        "    self.c = con.cursor()\n",
        "\n",
        "    # copy dictionary CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                                    \",term   VARCHAR \"\n",
        "                                    \",df     INTEGER \"\n",
        "                                    \",cf     INTEGER)\")\n",
        "    self.c.execute(\"COPY dict \"\n",
        "                   \"FROM '\" + dict + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy documents CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE docs(name  VARCHAR \"\n",
        "                                    \",docid INTEGER \"\n",
        "                                    \",len   INTEGER \"\n",
        "                                    \",temp  INTEGER)\")\n",
        "    self.c.execute(\"COPY docs \"\n",
        "                   \"FROM '\" + docs + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # copy terms CSV into DuckDB database\n",
        "    self.c.execute(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                                     \",docid  INTEGER \"\n",
        "                                     \",pos    INTEGER \"\n",
        "                                     \",tf     INTEGER)\")\n",
        "    self.c.execute(\"COPY terms \"\n",
        "                   \"FROM '\" + terms + \"' \"\n",
        "                   \"WITH DELIMITER '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in DuckDB database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    self.c.execute(\"DROP TABLE IF EXISTS query\")\n",
        "    self.c.execute(\"CREATE TABLE query(term VARCHAR)\")\n",
        "    self.c.execute(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on DuckDB database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by DuckDB\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = self.c.execute(query)\n",
        "    return out.fetchdf()\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = self.c.execute(\"SELECT SUM(dict.cf) \"\n",
        "                       \"FROM dict\")\n",
        "    return C.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = self.c.execute(\"SELECT COUNT(*) \"\n",
        "                       \"FROM docs\")\n",
        "    return N.fetchdf().iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = self.c.execute(\"SELECT AVG(docs.len) \"\n",
        "                           \"FROM docs\")\n",
        "    return avgdl.fetchdf().iloc[0, 0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting duckdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/45/37215c3e2fc9c5b94e379a0b3b85a388107d3d626cde8cfacea377ba1696/duckdb-0.1.1.tar.gz (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 6.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 10.2MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 11.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 12.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 153kB 10.2MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 194kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 215kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 225kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 235kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 256kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 266kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 276kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 296kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 307kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 317kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 337kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 348kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 358kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 368kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 378kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 389kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 399kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 409kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 419kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 430kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 440kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 450kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 471kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 481kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 491kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 501kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 512kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 522kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 532kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 542kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 552kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 563kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 573kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 583kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 593kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 604kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 614kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 624kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 634kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 645kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 655kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 665kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 675kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 686kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 696kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 706kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 716kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 727kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 737kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 747kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 757kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 768kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 778kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 788kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 798kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 808kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 819kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 829kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 839kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 849kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 860kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 870kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 880kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 890kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 901kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 911kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 921kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 931kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 942kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 952kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 962kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 972kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 983kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 993kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.0MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.0MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3MB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from duckdb) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from duckdb) (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->duckdb) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23->duckdb) (1.12.0)\n",
            "Building wheels for collected packages: duckdb\n",
            "  Building wheel for duckdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for duckdb: filename=duckdb-0.1.1-cp36-cp36m-linux_x86_64.whl size=1947901 sha256=aed9ade39cbbeb9318c40f860b8495b2aad53198495999e0da27e0fc787c8a65\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/2e/81/8061e62cf80a0ea73a4657d5807c46a93105440af5921e828c\n",
            "Successfully built duckdb\n",
            "Installing collected packages: duckdb\n",
            "Successfully installed duckdb-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YojwuWrTd6N",
        "colab_type": "code",
        "outputId": "c956b60e-31bf-4a56-f7f6-9ce70344deaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install monetdblite\n",
        "import monetdblite as m\n",
        "import pandas as pd\n",
        "\n",
        "class MonetDBLite(object):\n",
        "  \"\"\" \n",
        "  Class that houses all the MonetDBLite functionalities. \n",
        "\n",
        "  Attributes:\n",
        "    C     = [int] number of indexed terms\n",
        "    N     = [int] number of indexed documents\n",
        "    avgdl = [float] average number of terms per document\n",
        "    len_query = [int] number of terms in current search query\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               database='/tmp/MonetDBLite Database',\n",
        "               dict='/content/dict.csv',\n",
        "               docs='/content/docs.csv',\n",
        "               terms='/content/terms.csv'):\n",
        "    \"\"\"\n",
        "    Initializes MonetDBLite database with index.\n",
        "\n",
        "    Args:\n",
        "      database = [str] database path\n",
        "      dict     = [str] filename for dictionary CSV\n",
        "      docs     = [str] filename for documents CSV\n",
        "      terms    = [str] filename for terms CSV\n",
        "    \"\"\"\n",
        "    m.init(database)\n",
        "\n",
        "    # copy dictionary CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE dict(termid INTEGER \"\n",
        "                           \",term   VARCHAR(99) \"\n",
        "                           \",df     INTEGER \"\n",
        "                           \",cf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO dict \"\n",
        "          \"FROM '\" + dict + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy documents CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE docs(name  VARCHAR(99) \"\n",
        "                           \",docid INTEGER \"\n",
        "                           \",len   INTEGER \"\n",
        "                           \",temp  INTEGER)\") \n",
        "    m.sql(\"COPY INTO docs \"\n",
        "          \"FROM '\" + docs + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # copy terms CSV into MonetDBLite database\n",
        "    m.sql(\"CREATE TABLE terms(termid INTEGER \"\n",
        "                            \",docid  INTEGER \"\n",
        "                            \",pos    INTEGER \"\n",
        "                            \",tf     INTEGER)\")\n",
        "    m.sql(\"COPY INTO terms \"\n",
        "          \"FROM '\" + terms + \"' \"\n",
        "          \"USING DELIMITERS '|'\")\n",
        "    \n",
        "    # compute standard index statistics\n",
        "    self.C = self._C()\n",
        "    self.N = self._N()\n",
        "    self.avgdl = self._avgdl()\n",
        "    self.len_query = 0\n",
        "    \n",
        "  def make_query(self, *args: str):\n",
        "    \"\"\"\n",
        "    Makes query table in MonetDBLite database filled with query terms.\n",
        "    \n",
        "    Args:\n",
        "      args = [[str]] concatenation of strings to be made into a query\n",
        "    \"\"\"\n",
        "    query = \"('\" + args[0] + \"')\"\n",
        "    for arg in args[1:]:\n",
        "        query += \", ('\" + arg + \"')\"\n",
        "    \n",
        "    m.sql(\"DROP TABLE IF EXISTS query\")\n",
        "    m.sql(\"CREATE TABLE query(term VARCHAR(99))\")\n",
        "    m.sql(\"INSERT INTO query VALUES \" + query)\n",
        "\n",
        "    self.len_query = len(args)\n",
        "\n",
        "  def execute_query(self, query):\n",
        "    \"\"\"\n",
        "    Executes SQL query on MonetDBLite database.\n",
        "\n",
        "    Args:\n",
        "      query = [str] the SQL query to be executed by MonetDBLite\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The output of the execution as a Pandas DataFrame object.\n",
        "    \"\"\"\n",
        "    out = m.sql(query)\n",
        "    return pd.DataFrame.from_dict(out)\n",
        "\n",
        "  def _C(self):\n",
        "    \"\"\" \n",
        "    Gets total number of terms in the index.\n",
        "    \n",
        "    Returns [int]:\n",
        "      Total number of indexed terms.\n",
        "    \"\"\"\n",
        "    C = m.sql(\"SELECT SUM(dict.cf) \"\n",
        "              \"FROM dict\")\n",
        "    return pd.DataFrame.from_dict(C).iloc[0, 0]\n",
        "\n",
        "  def _N(self):\n",
        "    \"\"\"\n",
        "    Gets number of documents in the index.\n",
        "\n",
        "    Returns [int]:\n",
        "      Number of indexed documents.\n",
        "    \"\"\"\n",
        "    N = m.sql(\"SELECT COUNT(*) \"\n",
        "              \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(N).iloc[0, 0]\n",
        "\n",
        "  def _avgdl(self):\n",
        "    \"\"\"\n",
        "    Gets average number of terms per document in the index.\n",
        "\n",
        "    Returns [float]:\n",
        "      Average length of indexed documents.\n",
        "    \"\"\"\n",
        "    avgdl = m.sql(\"SELECT AVG(docs.len) \"\n",
        "                  \"FROM docs\")\n",
        "    return pd.DataFrame.from_dict(avgdl).iloc[0, 0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting monetdblite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/6a/d49c0b03c62c81098ecd42c6e2ed037979355d00797326a6acd2090f4822/monetdblite-0.6.3-cp36-cp36m-manylinux1_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from monetdblite) (1.17.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20->monetdblite) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.20->monetdblite) (1.12.0)\n",
            "Installing collected packages: monetdblite\n",
            "Successfully installed monetdblite-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p2vSKIYU9H4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Retriever(object):\n",
        "  \"\"\" Class to do document retrieval with term proximity using databases. \"\"\"     \n",
        "  def retrieve(self,\n",
        "               query, \n",
        "               db,\n",
        "               con_query=True, \n",
        "               pre_select='kld', \n",
        "               tp=True,\n",
        "               k=20,\n",
        "               sum=True,\n",
        "               mu=0.8, # totally not sure about this hyper-parameter\n",
        "               k1=1.2,\n",
        "               b=0.75,\n",
        "               num_docs=100,\n",
        "               max_span=5):\n",
        "    \"\"\"\n",
        "    Function that retreives documents with a Retrieval Status Value (RSV)\n",
        "    based on term-proximity (TP) weighting, Okapi BM25 or Kullback-Leibler\n",
        "    Divergence. When opting for TP, k documents can be pre-selected with\n",
        "    the Okapi BM25 or Kullback-Leibler Divergence retrieval models.\n",
        "\n",
        "    Args:\n",
        "      query      = [[str]] the tokenized and normalied query\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      tp         = [bool] whether to do the term proximity at all\n",
        "      k          = [int] maximum number of documents to retrieve with\n",
        "                         the pre-selection retrieval model\n",
        "      sum        = [bool] whether to sum the pre-selection and term \n",
        "                          proximity scores for the final score\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "      max_span   = [int] maximum distance, in number of terms, for a term\n",
        "                         pair to be included in the term proximity score\n",
        "\n",
        "    Returns [DataFrame]:\n",
        "      The Pandas DataFrame output.\n",
        "    \"\"\"\n",
        "    db.make_query(*query)\n",
        "\n",
        "    sql = (self._qterms(pre_select, tp) +\n",
        "           self._qtermstf(pre_select, tp) +\n",
        "           self._condocs(db, con_query, tp) +\n",
        "           self._pre_select_subscores(db, con_query, pre_select, mu, k1, b) +\n",
        "           self._topkdocs(pre_select, k) + \n",
        "           self._pairs(con_query, pre_select, tp, max_span) +\n",
        "           self._tpscores(db, tp, k1, b) +\n",
        "           self._scores(pre_select, tp, sum, num_docs))\n",
        "\n",
        "    return db.execute_query(sql)\n",
        "\n",
        "  def _qterms(self, pre_select, tp):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, including the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term  \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\"WITH qtermids \"\n",
        "                  \"AS (SELECT dict.termid \"\n",
        "                            \",dict.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM dict \"\n",
        "                      \"JOIN query \"\n",
        "                      \"ON dict.term = query.term\"\n",
        "                      \") \"\n",
        "             \"{}\")\n",
        "    \n",
        "    if tp:\n",
        "      query = query.format(\"{}\",\n",
        "                           \", qterms \"\n",
        "                           \"AS (SELECT terms.termid \"\n",
        "                                     \",terms.docid \"\n",
        "                                     \",terms.pos \"\n",
        "                                     \",terms.tf \"\n",
        "                                     \",qtermids.df \"\n",
        "                                     \"{}\"\n",
        "                               \"FROM terms \"\n",
        "                               \"JOIN qtermids \"\n",
        "                               \"ON terms.termid = qtermids.termid\"\n",
        "                               \") \")\n",
        "      if pre_select == 'kld':\n",
        "        return query.format(\",dict.cf \", \",qtermids.cf \")\n",
        "      else:\n",
        "        return query.format(\"\", \"\")\n",
        "    else:\n",
        "      if pre_select == 'kld':\n",
        "        return query.format(\",dict.cf \", \"\")\n",
        "      else:\n",
        "        return query.format(\"\", \"\")  \n",
        "\n",
        "  def _qtermstf(self, pre_select, tp):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to the query terms, excluding the positional information.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model;\n",
        "                   Kullback-Leibler Divergence retrieval model also needs\n",
        "                   collection frequency information of each term\n",
        "      tp         = [bool] whether to do the term proximity\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "    \n",
        "    query = (\", qtermstfrows \"\n",
        "                  \"AS (SELECT qterms.termid \"\n",
        "                            \",qterms.docid \"\n",
        "                            \",qterms.tf \"\n",
        "                            \"{}\"\n",
        "                            \"{}\"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                               \"OVER(PARTITION BY qterms.termid, qterms.docid \"\n",
        "                                    \"ORDER BY qterms.pos\"\n",
        "                                    \")\"\n",
        "                              \") AS row \"\n",
        "                      \"{}\" \n",
        "                      \") \"\n",
        "             \", qtermstf \"\n",
        "                  \"AS (SELECT qtermstfrows.termid \"\n",
        "                            \",qtermstfrows.docid \"\n",
        "                            \",qtermstfrows.tf \"\n",
        "                            \",qtermstfrows.df \"\n",
        "                            \"{}\"\n",
        "                      \"FROM qtermstfrows \"\n",
        "                      \"WHERE qtermstfrows.row = 1\"\n",
        "                      \") \")\n",
        "\n",
        "    if pre_select == 'kld':\n",
        "      if tp:\n",
        "        return query.format(\",qterms.df \",\n",
        "                            \",qterms.cf \",\n",
        "                            \"FROM qterms\",\n",
        "                            \",qtermstfrows.cf \")\n",
        "      else:\n",
        "        return query.format(\",qtermids.df \",\n",
        "                            \",qtermids.cf \",\n",
        "                            \"FROM terms AS qterms \"\n",
        "                            \"JOIN qtermids \"\n",
        "                            \"ON qterms.termid = qtermids.termid\",\n",
        "                            \",qtermstfrows.cf \")\n",
        "    elif pre_select == 'okapi':\n",
        "      if tp:\n",
        "        return query.format(\",qterms.df \",\n",
        "                            \"\",\n",
        "                            \"FROM qterms\",\n",
        "                            \"\")\n",
        "      else:\n",
        "        return query.format(\",qtermids.df \",\n",
        "                            \"\",\n",
        "                            \"FROM terms AS qterms \"\n",
        "                            \"JOIN qtermids \"\n",
        "                            \"ON qterms.termid = qtermids.termid\",\n",
        "                            \"\")\n",
        "\n",
        "  def _condocs(self, db, con_query, tp):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will retrieve the rows in the terms file\n",
        "    belonging to documents that contain all the query terms.\n",
        "\n",
        "    Args:\n",
        "      db        = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query = [bool] whether all query terms need to be in\n",
        "                         the document for it to be retrieved\n",
        "      tp         = [bool] whether to do the term proximity\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.                         \n",
        "    \"\"\"\n",
        "    if con_query:\n",
        "      query = (\", condocs \"\n",
        "                    \"AS (SELECT qterms.docid \"\n",
        "                        \"FROM {} AS qterms \"\n",
        "                        \"GROUP BY qterms.docid \"\n",
        "                        \"HAVING COUNT(DISTINCT qterms.termid) = {:d}\"\n",
        "                        \") \")\n",
        "      if tp:\n",
        "        return query.format(\"qterms\", db.len_query)\n",
        "      else:\n",
        "        return query.format(\"qtermstf\", db.len_query)\n",
        "    else:\n",
        "      return \"\"\n",
        "\n",
        "  def _pre_select_subscores(self, db, con_query, pre_select, mu, k1, b):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute a score for each \n",
        "    query term-document pair, according to the pre-selection\n",
        "    retrieval model.\n",
        "\n",
        "    Args:\n",
        "      db         = [DuckDB|MonetDBLite] database that stores the index\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved     \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      mu         = [float] hyper-parameter for the KLD retrieval model\n",
        "      k1         = [float] hyper-parameter for Okapi BM25\n",
        "      b          = [float] hyper-parameter for Okapi BM25\n",
        "    \n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'kld':\n",
        "      query = (\", kldsubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \",( LOG({:f}+tf*{:f}/cf)\"              \n",
        "                                  \"+\" \n",
        "                                 \"LOG(1/({:f}+len))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(mu, db.C, mu, \"{}\")\n",
        "    elif pre_select == 'okapi':\n",
        "      query = (\", okapisubscores \"\n",
        "                    \"AS (SELECT qtermstf.docid \"\n",
        "                              \",( LOG(({:f}-df+0.5)/(df+0.5))*tf*({:f}+1)\"\n",
        "                                  \"/\"\n",
        "                                 \"(tf+{:f}*(1-{:f}+{:f}*len/{:f}))\"\n",
        "                                \") AS subscore \"\n",
        "                        \"FROM qtermstf \"\n",
        "                        \"{}\"\n",
        "                        \"JOIN docs \"\n",
        "                        \"ON qtermstf.docid = docs.docid\"\n",
        "                        \") \")\n",
        "      query = query.format(db.N, k1, k1, b, b, db.avgdl, \"{}\")\n",
        "    else:\n",
        "      return \"\"\n",
        "\n",
        "    if con_query:\n",
        "      return query.format(\"JOIN condocs \"\n",
        "                          \"ON qtermstf.docid = condocs.docid \")\n",
        "    else:\n",
        "      return query.format(\"\")\n",
        "\n",
        "  def _topkdocs(self, pre_select, k):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the pre-selection scores,\n",
        "    according to the pre-selection retrieval model, and retrieve\n",
        "    the top k documents.\n",
        "\n",
        "    Args:\n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model\n",
        "      k          = [int] maximum number of documents retrieved with\n",
        "                       the pre-selection retrieval model\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if pre_select == 'none':\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", topdocs \"\n",
        "                  \"AS (SELECT subscores.docid \"\n",
        "                            \",SUM(subscores.subscore) AS score \"\n",
        "                            \",( ROW_NUMBER() \"\n",
        "                                \"OVER(ORDER BY SUM(subscores.subscore) DESC)\"\n",
        "                              \") AS row \"\n",
        "                      \"FROM {} AS subscores \"\n",
        "                      \"GROUP BY subscores.docid\"\n",
        "                      \") \"\n",
        "              \", topkdocs \"\n",
        "                  \"AS (SELECT topdocs.docid \"\n",
        "                            \",topdocs.score \"\n",
        "                      \"FROM topdocs \"\n",
        "                      \"WHERE topdocs.row BETWEEN 1 AND {:d}\"\n",
        "                      \") \")\n",
        "    \n",
        "    if pre_select == 'kld':\n",
        "      return query.format(\"kldsubscores\", k)\n",
        "    elif pre_select == 'okapi':\n",
        "      return query.format(\"okapisubscores\", k)\n",
        "\n",
        "  def _pairs(self, con_query, pre_select, tp, max_span):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term pair instance (tpi) for\n",
        "    each query term pair within a span of max_span terms.\n",
        "\n",
        "    Args:\n",
        "      con_query  = [bool] whether all query terms need to be in\n",
        "                          the document for it to be retrieved                          \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model  \n",
        "      tp         = [bool] whether to do the term proximity                   \n",
        "      max_span   = [int] the maximum span, in terms, of a term pair to\n",
        "                        include in the term proximity score\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "\n",
        "    query = (\", pairs \"\n",
        "                  \"AS (SELECT qterms1.termid AS termid1 \"\n",
        "                            \",qterms2.termid AS termid2 \"\n",
        "                            \",qterms1.docid \"\n",
        "                            \",1.0/(qterms1.pos-qterms2.pos) AS tpi \"\n",
        "                            \",( CASE WHEN qterms1.df > qterms2.df THEN qterms1.df \"\n",
        "                                    \"ELSE qterms2.df \"\n",
        "                               \"END\"\n",
        "                              \") AS maxdf \"\n",
        "                      \"FROM qterms AS qterms1 \"\n",
        "                      \"{}\"\n",
        "                      \"{}\"\n",
        "                      \"JOIN qterms AS qterms2 \"\n",
        "                      \"ON qterms1.docid = qterms2.docid AND \"\n",
        "                         \"NOT qterms1.termid = qterms2.termid AND \"\n",
        "                         \"qterms1.pos - qterms2.pos BETWEEN 1 AND {:d}\"\n",
        "                      \") \")\n",
        "    if con_query:\n",
        "      query = query.format(\"JOIN condocs ON qterms1.docid = condocs.docid \",\n",
        "                           \"{}\",\n",
        "                           max_span)\n",
        "    else:\n",
        "      query = query.format(\"\",\n",
        "                           \"{}\",\n",
        "                           max_span)\n",
        "      \n",
        "    if pre_select == 'none':\n",
        "      return query.format(\"\")\n",
        "    else:\n",
        "      return query.format(\"JOIN topkdocs ON qterms1.docid = topkdocs.docid \")\n",
        "      \n",
        "  def _tpscores(self, db, tp, k1, b):\n",
        "    \"\"\"\n",
        "    Get the SQL query that will compute the term proximity score.\n",
        "\n",
        "    Args:      \n",
        "      db        = [DuckDB|MonetDBLite] database that stores the index\n",
        "      tp       = [bool] whether to do the term proximity\n",
        "      k1       = [float] hyper-parameter for Okapi BM25\n",
        "      b        = [float] hyper-parameter for Okapi BM25\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    if not tp:\n",
        "      return \"\"\n",
        "      \n",
        "    query = (\",tpisums \"\n",
        "                  \"AS (SELECT pairs.termid1 \"\n",
        "                            \",pairs.termid2 \"\n",
        "                            \",pairs.docid \"\n",
        "                            \",SUM(pairs.tpi) AS tpisum \"\n",
        "                      \"FROM pairs \"              \n",
        "                      \"GROUP BY pairs.termid1 \"\n",
        "                              \",pairs.termid2 \"\n",
        "                              \",pairs.docid\"\n",
        "                      \") \"\n",
        "            \", tpsubscores \"\n",
        "                  \"AS (SELECT pairs.docid \"\n",
        "                            \",( LOG(({:f}-maxdf+0.5)/(maxdf+0.5))*tpisum*({:f}+1)\"\n",
        "                                \"/\"\n",
        "                              \"(tpisum+{:f}*(1-{:f}+{:f}*len/{:f}))\"\n",
        "                              \") AS tpsubscore \"\n",
        "                      \"FROM pairs \"\n",
        "                      \"JOIN tpisums \"\n",
        "                      \"ON pairs.termid1 = tpisums.termid1 AND \"\n",
        "                        \"pairs.termid2 = tpisums.termid2 AND \"\n",
        "                        \"pairs.docid = tpisums.docid \"\n",
        "                      \"JOIN docs \"\n",
        "                      \"ON pairs.docid = docs.docid\"\n",
        "                      \") \"\n",
        "            \", tpscores \"\n",
        "                  \"AS (SELECT tpsubscores.docid \"\n",
        "                            \",SUM(tpsubscores.tpsubscore) AS tpscore \"\n",
        "                      \"FROM tpsubscores \"\n",
        "                      \"GROUP BY tpsubscores.docid\"\n",
        "                      \") \")\n",
        "    return query.format(db.N, k1, k1, b, b, db.avgdl)\n",
        "\n",
        "  def _scores(self, pre_select, tp, sum, num_docs):\n",
        "    \"\"\" \n",
        "    Get the SQL query that will retrieve or compute the final document scores.\n",
        "\n",
        "    Args:      \n",
        "      pre_select = ['kld'|'okapi'|'none'] pre-selection retrieval model \n",
        "      tp         = [bool] whether to do the term proximity\n",
        "      sum        = [bool] whether to sum the pre-select and term \n",
        "                          proximity scores for the final score\n",
        "      num_docs   = [int] maximum number of documents to retrieve\n",
        "\n",
        "    Returns [str]:\n",
        "      SQL query as string.\n",
        "    \"\"\"\n",
        "    query = (\", scores \"\n",
        "                  \"AS ({}) \"\n",
        "             \"SELECT scores.docid \"\n",
        "                   \",scores.score \"\n",
        "             \"FROM scores \"\n",
        "             \"ORDER BY scores.score DESC \"\n",
        "             \"LIMIT {:d}\")\n",
        "    \n",
        "    if not tp:\n",
        "      return query.format(\"SELECT topkdocs.docid \"\n",
        "                                \",topkdocs.score \"\n",
        "                          \"FROM topkdocs\",\n",
        "                          num_docs)\n",
        "    elif pre_select == 'none' or not sum:\n",
        "      return query.format(\"SELECT tpscores.docid \"\n",
        "                                \",tpscores.tpscore AS score \"\n",
        "                          \"FROM tpscores\",\n",
        "                          num_docs)\n",
        "    else:\n",
        "      return query.format(\"SELECT topkdocs.docid \"\n",
        "                                \",( topkdocs.score\"\n",
        "                                    \"+\"\n",
        "                                   \"COALESCE(tpscores.tpscore, 0)\"\n",
        "                                  \") AS score \"\n",
        "                          \"FROM topkdocs \"\n",
        "                          \"LEFT JOIN tpscores \"\n",
        "                          \"ON topkdocs.docid = tpscores.docid\",\n",
        "                          num_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0DVuHD8yaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duck = DuckDB()\n",
        "monet = MonetDBLite()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvqmT_067S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retriever = Retriever()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgVPDEmB4Igm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d85f0f4a-31db-4a58-c996-7c91f7b98da5"
      },
      "source": [
        "query = ['new', 'york']\n",
        "\n",
        "duck_time = datetime.now()\n",
        "duck_scores = retriever.retrieve(query, duck)\n",
        "duck_time = datetime.now() - duck_time\n",
        "print(\"DuckDB query time: {}\".format(duck_time))\n",
        "\n",
        "monet_time = datetime.now()\n",
        "monet_scores = retriever.retrieve(query, monet)\n",
        "monet_time = datetime.now() - monet_time\n",
        "print(\"MonetDBLite query time: {}\".format(monet_time))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DuckDB query time: 0:00:13.023675\n",
            "MonetDBLite query time: 0:00:00.375717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nDcip3n5UyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "e80c6226-efcd-4985-d976-2c46a2d75646"
      },
      "source": [
        "duck_scores"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50961</td>\n",
              "      <td>59.406660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100831</td>\n",
              "      <td>18.508918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>330675</td>\n",
              "      <td>13.951959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>254096</td>\n",
              "      <td>11.489001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>323541</td>\n",
              "      <td>10.929049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>187978</td>\n",
              "      <td>8.859076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60420</td>\n",
              "      <td>7.729182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>256566</td>\n",
              "      <td>6.604098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>134955</td>\n",
              "      <td>5.923230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>111825</td>\n",
              "      <td>5.485813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>139111</td>\n",
              "      <td>5.268650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>268165</td>\n",
              "      <td>4.739824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>58689</td>\n",
              "      <td>4.705529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5474</td>\n",
              "      <td>4.644575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>262129</td>\n",
              "      <td>4.322686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>25012</td>\n",
              "      <td>4.153059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>204849</td>\n",
              "      <td>4.037683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>329326</td>\n",
              "      <td>4.037683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>101661</td>\n",
              "      <td>4.037683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>240113</td>\n",
              "      <td>4.002227</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     docid      score\n",
              "0    50961  59.406660\n",
              "1   100831  18.508918\n",
              "2   330675  13.951959\n",
              "3   254096  11.489001\n",
              "4   323541  10.929049\n",
              "5   187978   8.859076\n",
              "6    60420   7.729182\n",
              "7   256566   6.604098\n",
              "8   134955   5.923230\n",
              "9   111825   5.485813\n",
              "10  139111   5.268650\n",
              "11  268165   4.739824\n",
              "12   58689   4.705529\n",
              "13    5474   4.644575\n",
              "14  262129   4.322686\n",
              "15   25012   4.153059\n",
              "16  204849   4.037683\n",
              "17  329326   4.037683\n",
              "18  101661   4.037683\n",
              "19  240113   4.002227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gn2sGid5XyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "22e99253-d1fd-42ad-d919-b3515267da3a"
      },
      "source": [
        "monet_scores"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50961</td>\n",
              "      <td>136.788891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100831</td>\n",
              "      <td>42.618359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>330675</td>\n",
              "      <td>32.125574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>254096</td>\n",
              "      <td>26.454403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>323541</td>\n",
              "      <td>25.165066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>187978</td>\n",
              "      <td>20.398776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60420</td>\n",
              "      <td>17.797100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>256566</td>\n",
              "      <td>15.206498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>134955</td>\n",
              "      <td>13.638742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>111825</td>\n",
              "      <td>12.631551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>139111</td>\n",
              "      <td>12.131516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>268165</td>\n",
              "      <td>10.913848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>58689</td>\n",
              "      <td>10.834880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5474</td>\n",
              "      <td>10.694529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>262129</td>\n",
              "      <td>9.953352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>25012</td>\n",
              "      <td>9.562771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>101661</td>\n",
              "      <td>9.297108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>329326</td>\n",
              "      <td>9.297108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>204849</td>\n",
              "      <td>9.297108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>200431</td>\n",
              "      <td>9.215469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     docid       score\n",
              "0    50961  136.788891\n",
              "1   100831   42.618359\n",
              "2   330675   32.125574\n",
              "3   254096   26.454403\n",
              "4   323541   25.165066\n",
              "5   187978   20.398776\n",
              "6    60420   17.797100\n",
              "7   256566   15.206498\n",
              "8   134955   13.638742\n",
              "9   111825   12.631551\n",
              "10  139111   12.131516\n",
              "11  268165   10.913848\n",
              "12   58689   10.834880\n",
              "13    5474   10.694529\n",
              "14  262129    9.953352\n",
              "15   25012    9.562771\n",
              "16  101661    9.297108\n",
              "17  329326    9.297108\n",
              "18  204849    9.297108\n",
              "19  200431    9.215469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}